// This file is @generated by prost-build.
/// API key information.
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct ApiKey {
    /// A redacted API key. The full API key will not be displayed after it has
    /// been created.
    #[prost(string, tag = "1")]
    pub redacted_api_key: ::prost::alloc::string::String,
    /// ID of the user who created this API key.
    #[prost(string, tag = "3")]
    pub user_id: ::prost::alloc::string::String,
    /// Human-readable name for the API key.
    #[prost(string, tag = "4")]
    pub name: ::prost::alloc::string::String,
    /// Unix timestamp when the API key was created.
    #[prost(message, optional, tag = "5")]
    pub create_time: ::core::option::Option<::prost_wkt_types::Timestamp>,
    /// Unix timestamp when the API key was last modified.
    #[prost(message, optional, tag = "9")]
    pub modify_time: ::core::option::Option<::prost_wkt_types::Timestamp>,
    /// ID of the last user who modified the API key
    #[prost(string, tag = "11")]
    pub modified_by: ::prost::alloc::string::String,
    /// ID of the team this API key belongs to.
    #[prost(string, tag = "6")]
    pub team_id: ::prost::alloc::string::String,
    /// Access Control Lists (ACLs) associated with this key.
    /// These indicate the resources that the API key has access to.
    #[prost(string, repeated, tag = "7")]
    pub acls: ::prost::alloc::vec::Vec<::prost::alloc::string::String>,
    /// The ID of the API key. This is different from the API key itself.
    #[prost(string, tag = "8")]
    pub api_key_id: ::prost::alloc::string::String,
    /// Whether the API key is currently blocked from making API requests.
    #[prost(bool, tag = "10")]
    pub api_key_blocked: bool,
    /// Whether the team is currently blocked from making API requests.
    #[prost(bool, tag = "13")]
    pub team_blocked: bool,
    /// Whether the API key is currently disabled.
    #[prost(bool, tag = "12")]
    pub disabled: bool,
}
/// Generated client implementations.
pub mod auth_client {
    #![allow(
        unused_variables,
        dead_code,
        missing_docs,
        clippy::wildcard_imports,
        clippy::let_unit_value,
    )]
    use tonic::codegen::*;
    use tonic::codegen::http::Uri;
    /// An API service to check status of an API key.
    #[derive(Debug, Clone)]
    pub struct AuthClient<T> {
        inner: tonic::client::Grpc<T>,
    }
    impl AuthClient<tonic::transport::Channel> {
        /// Attempt to create a new client by connecting to a given endpoint.
        pub async fn connect<D>(dst: D) -> Result<Self, tonic::transport::Error>
        where
            D: TryInto<tonic::transport::Endpoint>,
            D::Error: Into<StdError>,
        {
            let conn = tonic::transport::Endpoint::new(dst)?.connect().await?;
            Ok(Self::new(conn))
        }
    }
    impl<T> AuthClient<T>
    where
        T: tonic::client::GrpcService<tonic::body::Body>,
        T::Error: Into<StdError>,
        T::ResponseBody: Body<Data = Bytes> + std::marker::Send + 'static,
        <T::ResponseBody as Body>::Error: Into<StdError> + std::marker::Send,
    {
        pub fn new(inner: T) -> Self {
            let inner = tonic::client::Grpc::new(inner);
            Self { inner }
        }
        pub fn with_origin(inner: T, origin: Uri) -> Self {
            let inner = tonic::client::Grpc::with_origin(inner, origin);
            Self { inner }
        }
        pub fn with_interceptor<F>(
            inner: T,
            interceptor: F,
        ) -> AuthClient<InterceptedService<T, F>>
        where
            F: tonic::service::Interceptor,
            T::ResponseBody: Default,
            T: tonic::codegen::Service<
                http::Request<tonic::body::Body>,
                Response = http::Response<
                    <T as tonic::client::GrpcService<tonic::body::Body>>::ResponseBody,
                >,
            >,
            <T as tonic::codegen::Service<
                http::Request<tonic::body::Body>,
            >>::Error: Into<StdError> + std::marker::Send + std::marker::Sync,
        {
            AuthClient::new(InterceptedService::new(inner, interceptor))
        }
        /// Compress requests with the given encoding.
        ///
        /// This requires the server to support it otherwise it might respond with an
        /// error.
        #[must_use]
        pub fn send_compressed(mut self, encoding: CompressionEncoding) -> Self {
            self.inner = self.inner.send_compressed(encoding);
            self
        }
        /// Enable decompressing responses.
        #[must_use]
        pub fn accept_compressed(mut self, encoding: CompressionEncoding) -> Self {
            self.inner = self.inner.accept_compressed(encoding);
            self
        }
        /// Limits the maximum size of a decoded message.
        ///
        /// Default: `4MB`
        #[must_use]
        pub fn max_decoding_message_size(mut self, limit: usize) -> Self {
            self.inner = self.inner.max_decoding_message_size(limit);
            self
        }
        /// Limits the maximum size of an encoded message.
        ///
        /// Default: `usize::MAX`
        #[must_use]
        pub fn max_encoding_message_size(mut self, limit: usize) -> Self {
            self.inner = self.inner.max_encoding_message_size(limit);
            self
        }
        /// Returns some information about an API key.
        pub async fn get_api_key_info(
            &mut self,
            request: impl tonic::IntoRequest<()>,
        ) -> std::result::Result<tonic::Response<super::ApiKey>, tonic::Status> {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::unknown(
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic_prost::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/xai_api.Auth/get_api_key_info",
            );
            let mut req = request.into_request();
            req.extensions_mut()
                .insert(GrpcMethod::new("xai_api.Auth", "get_api_key_info"));
            self.inner.unary(req, path, codec).await
        }
    }
}
/// The response from the service, when creating a deferred completion request.
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct StartDeferredResponse {
    /// The ID of this request. This ID can be used to retrieve completion results
    /// later.
    #[prost(string, tag = "1")]
    pub request_id: ::prost::alloc::string::String,
}
/// Retrieve the deferred chat request's response with the `request_id` in
/// StartDeferredResponse.
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct GetDeferredRequest {
    /// The ID of this request to get.
    #[prost(string, tag = "1")]
    pub request_id: ::prost::alloc::string::String,
}
/// Status of deferred completion request.
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration)]
#[repr(i32)]
pub enum DeferredStatus {
    /// Invalid status.
    InvalidDeferredStatus = 0,
    /// The request has been processed and is available for download.
    Done = 1,
    /// The request has been processed but the content has expired and is not
    /// available anymore.
    Expired = 2,
    /// The request is still being processed.
    Pending = 3,
}
impl DeferredStatus {
    /// String value of the enum field names used in the ProtoBuf definition.
    ///
    /// The values are not transformed in any way and thus are considered stable
    /// (if the ProtoBuf definition does not change) and safe for programmatic use.
    pub fn as_str_name(&self) -> &'static str {
        match self {
            Self::InvalidDeferredStatus => "INVALID_DEFERRED_STATUS",
            Self::Done => "DONE",
            Self::Expired => "EXPIRED",
            Self::Pending => "PENDING",
        }
    }
    /// Creates an enum from field names used in the ProtoBuf definition.
    pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
        match value {
            "INVALID_DEFERRED_STATUS" => Some(Self::InvalidDeferredStatus),
            "DONE" => Some(Self::Done),
            "EXPIRED" => Some(Self::Expired),
            "PENDING" => Some(Self::Pending),
            _ => None,
        }
    }
}
/// Document search using a combination of keyword and semantic search.
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct HybridRetrieval {
    /// Overfetch multiplier applied to the requested search limit.
    /// When set, fetches (limit * search_multiplier) results from each retrieval method
    /// before reranking, then returns the top `limit` results after reranking.
    /// Valid range is \[1, 100\]. Defaults to 1 when unset.
    #[prost(int32, optional, tag = "1")]
    pub search_multiplier: ::core::option::Option<i32>,
    /// Which reranker to use to limit results to the desired value.
    #[prost(oneof = "hybrid_retrieval::Reranker", tags = "2, 3")]
    pub reranker: ::core::option::Option<hybrid_retrieval::Reranker>,
}
/// Nested message and enum types in `HybridRetrieval`.
pub mod hybrid_retrieval {
    /// Which reranker to use to limit results to the desired value.
    #[derive(serde::Serialize, serde::Deserialize)]
    #[derive(Clone, PartialEq, ::prost::Oneof)]
    pub enum Reranker {
        /// Use a reranker model to perform the reranking.
        #[prost(message, tag = "2")]
        RerankerModel(super::RerankerModel),
        /// Use RRF to perform the reranking.
        #[prost(message, tag = "3")]
        ReciprocalRankFusion(super::ReciprocalRankFusion),
    }
}
/// Document search using keyword matching (sparse embeddings).
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct KeywordRetrieval {
    /// Optional, but always used when doing search across multiple collections.
    #[prost(message, optional, tag = "1")]
    pub reranker: ::core::option::Option<RerankerModel>,
}
/// Document search using semantic similarity (dense embeddings).
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct SemanticRetrieval {
    /// Optional, but always used when doing search across multiple collections.
    #[prost(message, optional, tag = "1")]
    pub reranker: ::core::option::Option<RerankerModel>,
}
/// Configuration for reciprocal rank fusion (RRF) reranking.
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, Copy, PartialEq, ::prost::Message)]
pub struct ReciprocalRankFusion {
    /// The RRF constant k used in the reciprocal rank fusion formula. Defaults to 60.
    #[prost(int32, optional, tag = "1")]
    pub k: ::core::option::Option<i32>,
    /// Weight for embedding (dense) search results. Should be between 0 and 1. Defaults to 0.5.
    #[prost(float, tag = "3")]
    pub embedding_weight: f32,
    /// Weight for keyword (sparse) search results. Should be between 0 and 1. Defaults to 0.5.
    #[prost(float, tag = "4")]
    pub text_weight: f32,
}
/// Configuration for model-based reranking.
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct RerankerModel {
    /// The model to use for reranking. Defaults to standard reranker model.
    #[prost(string, optional, tag = "1")]
    pub model: ::core::option::Option<::prost::alloc::string::String>,
    /// Instructions for the reranking model. Defaults to generic reranking instructions.
    #[prost(string, optional, tag = "2")]
    pub instructions: ::core::option::Option<::prost::alloc::string::String>,
}
/// Message that contains settings needed to do a document search.
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct SearchRequest {
    /// The query to search for which will be embedded using the
    /// same embedding model as the one used for the source to query.
    #[prost(string, tag = "1")]
    pub query: ::prost::alloc::string::String,
    /// The source to query.
    #[prost(message, optional, tag = "2")]
    pub source: ::core::option::Option<DocumentsSource>,
    /// The number of chunks to return.
    /// Will always return the top matching chunks.
    /// Optional, defaults to 10.
    #[prost(int32, optional, tag = "3")]
    pub limit: ::core::option::Option<i32>,
    /// User-defined instructions to be included in the search query. Defaults to generic search instructions.
    #[prost(string, optional, tag = "5")]
    pub instructions: ::core::option::Option<::prost::alloc::string::String>,
    /// Deprecated: Metric now comes from what is set during collection creation.
    #[deprecated]
    #[prost(enumeration = "RankingMetric", optional, tag = "4")]
    pub ranking_metric: ::core::option::Option<i32>,
    /// How to perform the document search. Defaults to HybridRetrieval
    #[prost(oneof = "search_request::RetrievalMode", tags = "11, 12, 13")]
    pub retrieval_mode: ::core::option::Option<search_request::RetrievalMode>,
}
/// Nested message and enum types in `SearchRequest`.
pub mod search_request {
    /// How to perform the document search. Defaults to HybridRetrieval
    #[derive(serde::Serialize, serde::Deserialize)]
    #[derive(Clone, PartialEq, ::prost::Oneof)]
    pub enum RetrievalMode {
        #[prost(message, tag = "11")]
        HybridRetrieval(super::HybridRetrieval),
        #[prost(message, tag = "12")]
        SemanticRetrieval(super::SemanticRetrieval),
        #[prost(message, tag = "13")]
        KeywordRetrieval(super::KeywordRetrieval),
    }
}
/// SearchResponse message contains the results of a document search operation.
/// It returns a collection of matching document chunks sorted by relevance score.
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct SearchResponse {
    /// Collection of document chunks that match the search query, ordered by relevance score
    /// from highest to lowest.
    #[prost(message, repeated, tag = "1")]
    pub matches: ::prost::alloc::vec::Vec<SearchMatch>,
}
/// SearchMatch message represents a single document chunk that matches the search query.
/// It contains the document ID, chunk ID, content text, and a relevance score indicating
/// how well it matches the query.
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct SearchMatch {
    /// Unique identifier of the document that contains the matching chunk.
    #[prost(string, tag = "1")]
    pub file_id: ::prost::alloc::string::String,
    /// Unique identifier of the specific chunk within the document that matched the search query.
    #[prost(string, tag = "2")]
    pub chunk_id: ::prost::alloc::string::String,
    /// The actual text content of the matching chunk that can be presented to the user.
    #[prost(string, tag = "3")]
    pub chunk_content: ::prost::alloc::string::String,
    /// Score is the score of the chunk, which is determined by the ranking metric.
    /// For L2 distance, lower scores indicate better matches. Range is \[0, inf).
    /// For cosine similarity, higher scores indicate better matches. Range is \[0, 1\].
    #[prost(float, tag = "4")]
    pub score: f32,
    /// The ID(s) of the collection(s) to which this document belongs.
    #[prost(string, repeated, tag = "5")]
    pub collection_ids: ::prost::alloc::vec::Vec<::prost::alloc::string::String>,
}
/// Configuration for a documents sources in search requests.
///
/// This message configures a source for search content within documents or collections of documents.
/// Those documents must be uploaded through the management API or directly on the xAI console:
/// <https://console.x.ai.>
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct DocumentsSource {
    /// IDs of collections to use.
    #[prost(string, repeated, tag = "1")]
    pub collection_ids: ::prost::alloc::vec::Vec<::prost::alloc::string::String>,
}
/// RankingMetric is the metric to use for the search.
/// Deprecated: Metric now comes from what is set in the collection creation.
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration)]
#[repr(i32)]
pub enum RankingMetric {
    Unknown = 0,
    L2Distance = 1,
    CosineSimilarity = 2,
}
impl RankingMetric {
    /// String value of the enum field names used in the ProtoBuf definition.
    ///
    /// The values are not transformed in any way and thus are considered stable
    /// (if the ProtoBuf definition does not change) and safe for programmatic use.
    pub fn as_str_name(&self) -> &'static str {
        match self {
            Self::Unknown => "RANKING_METRIC_UNKNOWN",
            Self::L2Distance => "RANKING_METRIC_L2_DISTANCE",
            Self::CosineSimilarity => "RANKING_METRIC_COSINE_SIMILARITY",
        }
    }
    /// Creates an enum from field names used in the ProtoBuf definition.
    pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
        match value {
            "RANKING_METRIC_UNKNOWN" => Some(Self::Unknown),
            "RANKING_METRIC_L2_DISTANCE" => Some(Self::L2Distance),
            "RANKING_METRIC_COSINE_SIMILARITY" => Some(Self::CosineSimilarity),
            _ => None,
        }
    }
}
/// Generated client implementations.
pub mod documents_client {
    #![allow(
        unused_variables,
        dead_code,
        missing_docs,
        clippy::wildcard_imports,
        clippy::let_unit_value,
    )]
    use tonic::codegen::*;
    use tonic::codegen::http::Uri;
    #[derive(Debug, Clone)]
    pub struct DocumentsClient<T> {
        inner: tonic::client::Grpc<T>,
    }
    impl DocumentsClient<tonic::transport::Channel> {
        /// Attempt to create a new client by connecting to a given endpoint.
        pub async fn connect<D>(dst: D) -> Result<Self, tonic::transport::Error>
        where
            D: TryInto<tonic::transport::Endpoint>,
            D::Error: Into<StdError>,
        {
            let conn = tonic::transport::Endpoint::new(dst)?.connect().await?;
            Ok(Self::new(conn))
        }
    }
    impl<T> DocumentsClient<T>
    where
        T: tonic::client::GrpcService<tonic::body::Body>,
        T::Error: Into<StdError>,
        T::ResponseBody: Body<Data = Bytes> + std::marker::Send + 'static,
        <T::ResponseBody as Body>::Error: Into<StdError> + std::marker::Send,
    {
        pub fn new(inner: T) -> Self {
            let inner = tonic::client::Grpc::new(inner);
            Self { inner }
        }
        pub fn with_origin(inner: T, origin: Uri) -> Self {
            let inner = tonic::client::Grpc::with_origin(inner, origin);
            Self { inner }
        }
        pub fn with_interceptor<F>(
            inner: T,
            interceptor: F,
        ) -> DocumentsClient<InterceptedService<T, F>>
        where
            F: tonic::service::Interceptor,
            T::ResponseBody: Default,
            T: tonic::codegen::Service<
                http::Request<tonic::body::Body>,
                Response = http::Response<
                    <T as tonic::client::GrpcService<tonic::body::Body>>::ResponseBody,
                >,
            >,
            <T as tonic::codegen::Service<
                http::Request<tonic::body::Body>,
            >>::Error: Into<StdError> + std::marker::Send + std::marker::Sync,
        {
            DocumentsClient::new(InterceptedService::new(inner, interceptor))
        }
        /// Compress requests with the given encoding.
        ///
        /// This requires the server to support it otherwise it might respond with an
        /// error.
        #[must_use]
        pub fn send_compressed(mut self, encoding: CompressionEncoding) -> Self {
            self.inner = self.inner.send_compressed(encoding);
            self
        }
        /// Enable decompressing responses.
        #[must_use]
        pub fn accept_compressed(mut self, encoding: CompressionEncoding) -> Self {
            self.inner = self.inner.accept_compressed(encoding);
            self
        }
        /// Limits the maximum size of a decoded message.
        ///
        /// Default: `4MB`
        #[must_use]
        pub fn max_decoding_message_size(mut self, limit: usize) -> Self {
            self.inner = self.inner.max_decoding_message_size(limit);
            self
        }
        /// Limits the maximum size of an encoded message.
        ///
        /// Default: `usize::MAX`
        #[must_use]
        pub fn max_encoding_message_size(mut self, limit: usize) -> Self {
            self.inner = self.inner.max_encoding_message_size(limit);
            self
        }
        pub async fn search(
            &mut self,
            request: impl tonic::IntoRequest<super::SearchRequest>,
        ) -> std::result::Result<tonic::Response<super::SearchResponse>, tonic::Status> {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::unknown(
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic_prost::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static("/xai_api.Documents/Search");
            let mut req = request.into_request();
            req.extensions_mut().insert(GrpcMethod::new("xai_api.Documents", "Search"));
            self.inner.unary(req, path, codec).await
        }
    }
}
/// Request message for generating an image.
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct GenerateImageRequest {
    /// Input prompt to generate an image from.
    #[prost(string, tag = "1")]
    pub prompt: ::prost::alloc::string::String,
    /// Optional input image to perform generations based on.
    #[prost(message, optional, tag = "5")]
    pub image: ::core::option::Option<ImageUrlContent>,
    /// Name or alias of the image generation model to be used.
    #[prost(string, tag = "2")]
    pub model: ::prost::alloc::string::String,
    /// Number of images to generate. Allowed values are \[1, 10\].
    #[prost(int32, optional, tag = "3")]
    pub n: ::core::option::Option<i32>,
    /// An opaque string supplied by the API client (customer) to identify a user.
    /// The string will be stored in the logs and can be used in customer service
    /// requests to identify certain requests.
    #[prost(string, tag = "4")]
    pub user: ::prost::alloc::string::String,
    /// Optional field to specify the image format to return the generated image(s)
    /// in. See ImageFormat enum for options.
    #[prost(enumeration = "ImageFormat", tag = "11")]
    pub format: i32,
}
/// The response from the image generation models containing the generated image(s).
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ImageResponse {
    /// A list of generated images (including relevant metadata).
    #[prost(message, repeated, tag = "1")]
    pub images: ::prost::alloc::vec::Vec<GeneratedImage>,
    /// The model used to generate the image (ignoring aliases).
    #[prost(string, tag = "2")]
    pub model: ::prost::alloc::string::String,
}
/// Contains all data related to a generated image.
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct GeneratedImage {
    /// The up sampled prompt that was used to generate the image.
    #[prost(string, tag = "2")]
    pub up_sampled_prompt: ::prost::alloc::string::String,
    /// Whether the image generated by the model respects moderation rules.
    /// The field will be true if the image respect moderation rules. Otherwise
    /// the field will be false and the image field is replaced by a placeholder.
    #[prost(bool, tag = "4")]
    pub respect_moderation: bool,
    /// The generated image.
    #[prost(oneof = "generated_image::Image", tags = "1, 3")]
    pub image: ::core::option::Option<generated_image::Image>,
}
/// Nested message and enum types in `GeneratedImage`.
pub mod generated_image {
    /// The generated image.
    #[derive(serde::Serialize, serde::Deserialize)]
    #[derive(Clone, PartialEq, Eq, Hash, ::prost::Oneof)]
    pub enum Image {
        /// A base-64 encoded string of the image.
        #[prost(string, tag = "1")]
        Base64(::prost::alloc::string::String),
        /// A url that points to the generated image.
        #[prost(string, tag = "3")]
        Url(::prost::alloc::string::String),
    }
}
/// Contains data relating to an image that is provided to the model.
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct ImageUrlContent {
    /// This is either an image URL or a base64-encoded version of the image.
    /// The following image formats are supported: PNG and JPG.
    /// If an image URL is provided, the image will be downloaded for every API
    /// request without being cached. Images are fetched using
    /// "XaiImageApiFetch/1.0" user agent, and will timeout after 5 seconds.
    /// The image size is limited to 10 MiB. If the image download fails, the API
    /// request will fail as well.
    #[prost(string, tag = "1")]
    pub image_url: ::prost::alloc::string::String,
    /// The level of pre-processing resolution that will be applied to the image.
    #[prost(enumeration = "ImageDetail", tag = "2")]
    pub detail: i32,
}
/// Indicates the level of preprocessing to apply to images that will be fed to
/// the model.
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration)]
#[repr(i32)]
pub enum ImageDetail {
    /// Detail level is invalid.
    DetailInvalid = 0,
    /// The system will decide the image resolution to use.
    DetailAuto = 1,
    /// The model will process a low-resolution version of the image. This is
    /// faster and cheaper (i.e. consumes fewer tokens).
    DetailLow = 2,
    /// The model will process a high-resolution of the image. This is slower and
    /// more expensive but will allow the model to attend to more nuanced details
    /// in the image.
    DetailHigh = 3,
}
impl ImageDetail {
    /// String value of the enum field names used in the ProtoBuf definition.
    ///
    /// The values are not transformed in any way and thus are considered stable
    /// (if the ProtoBuf definition does not change) and safe for programmatic use.
    pub fn as_str_name(&self) -> &'static str {
        match self {
            Self::DetailInvalid => "DETAIL_INVALID",
            Self::DetailAuto => "DETAIL_AUTO",
            Self::DetailLow => "DETAIL_LOW",
            Self::DetailHigh => "DETAIL_HIGH",
        }
    }
    /// Creates an enum from field names used in the ProtoBuf definition.
    pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
        match value {
            "DETAIL_INVALID" => Some(Self::DetailInvalid),
            "DETAIL_AUTO" => Some(Self::DetailAuto),
            "DETAIL_LOW" => Some(Self::DetailLow),
            "DETAIL_HIGH" => Some(Self::DetailHigh),
            _ => None,
        }
    }
}
/// The image format to be returned (base-64 encoded string or a url of
/// the image).
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration)]
#[repr(i32)]
pub enum ImageFormat {
    /// Image format is invalid.
    ImgFormatInvalid = 0,
    /// A base-64 encoding of the image.
    ImgFormatBase64 = 1,
    /// An URL at which the user can download the image.
    ImgFormatUrl = 2,
}
impl ImageFormat {
    /// String value of the enum field names used in the ProtoBuf definition.
    ///
    /// The values are not transformed in any way and thus are considered stable
    /// (if the ProtoBuf definition does not change) and safe for programmatic use.
    pub fn as_str_name(&self) -> &'static str {
        match self {
            Self::ImgFormatInvalid => "IMG_FORMAT_INVALID",
            Self::ImgFormatBase64 => "IMG_FORMAT_BASE64",
            Self::ImgFormatUrl => "IMG_FORMAT_URL",
        }
    }
    /// Creates an enum from field names used in the ProtoBuf definition.
    pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
        match value {
            "IMG_FORMAT_INVALID" => Some(Self::ImgFormatInvalid),
            "IMG_FORMAT_BASE64" => Some(Self::ImgFormatBase64),
            "IMG_FORMAT_URL" => Some(Self::ImgFormatUrl),
            _ => None,
        }
    }
}
/// Generated client implementations.
pub mod image_client {
    #![allow(
        unused_variables,
        dead_code,
        missing_docs,
        clippy::wildcard_imports,
        clippy::let_unit_value,
    )]
    use tonic::codegen::*;
    use tonic::codegen::http::Uri;
    /// An API service for interaction with image generation models.
    #[derive(Debug, Clone)]
    pub struct ImageClient<T> {
        inner: tonic::client::Grpc<T>,
    }
    impl ImageClient<tonic::transport::Channel> {
        /// Attempt to create a new client by connecting to a given endpoint.
        pub async fn connect<D>(dst: D) -> Result<Self, tonic::transport::Error>
        where
            D: TryInto<tonic::transport::Endpoint>,
            D::Error: Into<StdError>,
        {
            let conn = tonic::transport::Endpoint::new(dst)?.connect().await?;
            Ok(Self::new(conn))
        }
    }
    impl<T> ImageClient<T>
    where
        T: tonic::client::GrpcService<tonic::body::Body>,
        T::Error: Into<StdError>,
        T::ResponseBody: Body<Data = Bytes> + std::marker::Send + 'static,
        <T::ResponseBody as Body>::Error: Into<StdError> + std::marker::Send,
    {
        pub fn new(inner: T) -> Self {
            let inner = tonic::client::Grpc::new(inner);
            Self { inner }
        }
        pub fn with_origin(inner: T, origin: Uri) -> Self {
            let inner = tonic::client::Grpc::with_origin(inner, origin);
            Self { inner }
        }
        pub fn with_interceptor<F>(
            inner: T,
            interceptor: F,
        ) -> ImageClient<InterceptedService<T, F>>
        where
            F: tonic::service::Interceptor,
            T::ResponseBody: Default,
            T: tonic::codegen::Service<
                http::Request<tonic::body::Body>,
                Response = http::Response<
                    <T as tonic::client::GrpcService<tonic::body::Body>>::ResponseBody,
                >,
            >,
            <T as tonic::codegen::Service<
                http::Request<tonic::body::Body>,
            >>::Error: Into<StdError> + std::marker::Send + std::marker::Sync,
        {
            ImageClient::new(InterceptedService::new(inner, interceptor))
        }
        /// Compress requests with the given encoding.
        ///
        /// This requires the server to support it otherwise it might respond with an
        /// error.
        #[must_use]
        pub fn send_compressed(mut self, encoding: CompressionEncoding) -> Self {
            self.inner = self.inner.send_compressed(encoding);
            self
        }
        /// Enable decompressing responses.
        #[must_use]
        pub fn accept_compressed(mut self, encoding: CompressionEncoding) -> Self {
            self.inner = self.inner.accept_compressed(encoding);
            self
        }
        /// Limits the maximum size of a decoded message.
        ///
        /// Default: `4MB`
        #[must_use]
        pub fn max_decoding_message_size(mut self, limit: usize) -> Self {
            self.inner = self.inner.max_decoding_message_size(limit);
            self
        }
        /// Limits the maximum size of an encoded message.
        ///
        /// Default: `usize::MAX`
        #[must_use]
        pub fn max_encoding_message_size(mut self, limit: usize) -> Self {
            self.inner = self.inner.max_encoding_message_size(limit);
            self
        }
        /// Create an image based on a text prompt and optionally another image.
        pub async fn generate_image(
            &mut self,
            request: impl tonic::IntoRequest<super::GenerateImageRequest>,
        ) -> std::result::Result<tonic::Response<super::ImageResponse>, tonic::Status> {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::unknown(
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic_prost::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/xai_api.Image/GenerateImage",
            );
            let mut req = request.into_request();
            req.extensions_mut()
                .insert(GrpcMethod::new("xai_api.Image", "GenerateImage"));
            self.inner.unary(req, path, codec).await
        }
    }
}
/// Records the cost associated with a sampling request (both chat and sample
/// endpoints).
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct SamplingUsage {
    /// Total number of text completion tokens generated across all choices
    /// (in case of n>1).
    #[prost(int32, tag = "1")]
    pub completion_tokens: i32,
    /// Total number of reasoning tokens generated across all choices.
    #[prost(int32, tag = "6")]
    pub reasoning_tokens: i32,
    /// Total number of prompt tokens (both text and images).
    #[prost(int32, tag = "2")]
    pub prompt_tokens: i32,
    /// Total number of tokens (prompt + completion).
    #[prost(int32, tag = "3")]
    pub total_tokens: i32,
    /// Total number of (uncached) text tokens in the prompt.
    #[prost(int32, tag = "4")]
    pub prompt_text_tokens: i32,
    /// Total number of cached text tokens in the prompt.
    #[prost(int32, tag = "7")]
    pub cached_prompt_text_tokens: i32,
    /// Total number of image tokens in the prompt.
    #[prost(int32, tag = "5")]
    pub prompt_image_tokens: i32,
    /// Number of individual live search sources used.
    /// Only applicable when live search is enabled.
    /// e.g. If a live search query returns citations from both X and Web and news sources, this will be 3.
    /// If it returns citations from only X, this will be 1.
    #[prost(int32, tag = "8")]
    pub num_sources_used: i32,
    /// List of server side tools called.
    #[prost(enumeration = "ServerSideTool", repeated, tag = "9")]
    pub server_side_tools_used: ::prost::alloc::vec::Vec<i32>,
}
/// Usage of embedding models.
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, Copy, PartialEq, Eq, Hash, ::prost::Message)]
pub struct EmbeddingUsage {
    /// The number of feature vectors produced from text inputs.
    #[prost(int32, tag = "1")]
    pub num_text_embeddings: i32,
    /// The number of feature vectors produced from image inputs.
    #[prost(int32, tag = "2")]
    pub num_image_embeddings: i32,
}
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration)]
#[repr(i32)]
pub enum ServerSideTool {
    Invalid = 0,
    WebSearch = 1,
    XSearch = 2,
    CodeExecution = 3,
    ViewImage = 4,
    ViewXVideo = 5,
    CollectionsSearch = 6,
    Mcp = 7,
    AttachmentSearch = 8,
}
impl ServerSideTool {
    /// String value of the enum field names used in the ProtoBuf definition.
    ///
    /// The values are not transformed in any way and thus are considered stable
    /// (if the ProtoBuf definition does not change) and safe for programmatic use.
    pub fn as_str_name(&self) -> &'static str {
        match self {
            Self::Invalid => "SERVER_SIDE_TOOL_INVALID",
            Self::WebSearch => "SERVER_SIDE_TOOL_WEB_SEARCH",
            Self::XSearch => "SERVER_SIDE_TOOL_X_SEARCH",
            Self::CodeExecution => "SERVER_SIDE_TOOL_CODE_EXECUTION",
            Self::ViewImage => "SERVER_SIDE_TOOL_VIEW_IMAGE",
            Self::ViewXVideo => "SERVER_SIDE_TOOL_VIEW_X_VIDEO",
            Self::CollectionsSearch => "SERVER_SIDE_TOOL_COLLECTIONS_SEARCH",
            Self::Mcp => "SERVER_SIDE_TOOL_MCP",
            Self::AttachmentSearch => "SERVER_SIDE_TOOL_ATTACHMENT_SEARCH",
        }
    }
    /// Creates an enum from field names used in the ProtoBuf definition.
    pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
        match value {
            "SERVER_SIDE_TOOL_INVALID" => Some(Self::Invalid),
            "SERVER_SIDE_TOOL_WEB_SEARCH" => Some(Self::WebSearch),
            "SERVER_SIDE_TOOL_X_SEARCH" => Some(Self::XSearch),
            "SERVER_SIDE_TOOL_CODE_EXECUTION" => Some(Self::CodeExecution),
            "SERVER_SIDE_TOOL_VIEW_IMAGE" => Some(Self::ViewImage),
            "SERVER_SIDE_TOOL_VIEW_X_VIDEO" => Some(Self::ViewXVideo),
            "SERVER_SIDE_TOOL_COLLECTIONS_SEARCH" => Some(Self::CollectionsSearch),
            "SERVER_SIDE_TOOL_MCP" => Some(Self::Mcp),
            "SERVER_SIDE_TOOL_ATTACHMENT_SEARCH" => Some(Self::AttachmentSearch),
            _ => None,
        }
    }
}
/// Request to get a text completion response sampling.
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct SampleTextRequest {
    /// Text prompts to sample on.
    #[prost(string, repeated, tag = "1")]
    pub prompt: ::prost::alloc::vec::Vec<::prost::alloc::string::String>,
    /// Name or alias of the model to be used.
    #[prost(string, tag = "3")]
    pub model: ::prost::alloc::string::String,
    /// The number of completions to create concurrently. A single completion will
    /// be generated if the parameter is unset. Each completion is charged at the
    /// same rate. You can generate at most 128 concurrent completions.
    #[prost(int32, optional, tag = "8")]
    pub n: ::core::option::Option<i32>,
    /// The maximum number of tokens to sample. If unset, the model samples until
    /// one of the following stop-conditions is reached:
    ///
    /// * The context length of the model is exceeded
    /// * One of the `stop` sequences has been observed.
    ///
    /// We recommend choosing a reasonable value to reduce the risk of accidental
    /// long-generations that consume many tokens.
    #[prost(int32, optional, tag = "7")]
    pub max_tokens: ::core::option::Option<i32>,
    /// A random seed used to make the sampling process deterministic. This is
    /// provided in a best-effort basis without guarantee that sampling is 100%
    /// deterministic given a seed. This is primarily provided for short-lived
    /// testing purposes. Given a fixed request and seed, the answers may change
    /// over time as our systems evolve.
    #[prost(int32, optional, tag = "11")]
    pub seed: ::core::option::Option<i32>,
    /// String patterns that will cause the sampling procedure to stop prematurely
    /// when observed.
    /// Note that the completion is based on individual tokens and sampling can
    /// only terminate at token boundaries. If a stop string is a substring of an
    /// individual token, the completion will include the entire token, which
    /// extends beyond the stop string.
    /// For example, if `stop = \["wor"\]` and we prompt the model with "hello" to
    /// which it responds with "world", then the sampling procedure will stop after
    /// observing the "world" token and the completion will contain
    /// the entire world "world" even though the stop string was just "wor".
    /// You can provide at most 8 stop strings.
    #[prost(string, repeated, tag = "12")]
    pub stop: ::prost::alloc::vec::Vec<::prost::alloc::string::String>,
    /// A number between 0 and 2 used to control the variance of completions.
    /// The smaller the value, the more deterministic the model will become. For
    /// example, if we sample 1000 answers to the same prompt at a temperature of
    /// 0.001, then most of the 1000 answers will be identical. Conversely, if we
    /// conduct the same experiment at a temperature of 2, virtually no two answers
    /// will be identical. Note that increasing the temperature will cause
    /// the model to hallucinate more strongly.
    #[prost(float, optional, tag = "14")]
    pub temperature: ::core::option::Option<f32>,
    /// A number between 0 and 1 controlling the likelihood of the model to use
    /// less-common answers. Recall that the model produces a probability for
    /// each token. This means, for any choice of token there are thousands of
    /// possibilities to choose from. This parameter controls the "nucleus sampling
    /// algorithm". Instead of considering every possible token at every step, we
    /// only look at the K tokens who's probabilities exceed `top_p`.
    /// For example, if we set `top_p = 0.9`, then the set of tokens we actually
    /// sample from, will have a probability mass of at least 90%. In practice,
    /// low values will make the model more deterministic.
    #[prost(float, optional, tag = "15")]
    pub top_p: ::core::option::Option<f32>,
    /// Number between -2.0 and 2.0.
    /// Positive values penalize new tokens based on their existing frequency in the text so far,
    /// decreasing the model's likelihood to repeat the same line verbatim.
    #[prost(float, optional, tag = "13")]
    pub frequency_penalty: ::core::option::Option<f32>,
    /// Whether to return log probabilities of the output tokens or not.
    /// If true, returns the log probabilities of each output token returned in the content of message.
    #[prost(bool, tag = "5")]
    pub logprobs: bool,
    /// Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.
    /// Not supported by grok-3 models.
    #[prost(float, optional, tag = "9")]
    pub presence_penalty: ::core::option::Option<f32>,
    /// An integer between 0 and 8 specifying the number of most likely tokens to return at each token position,
    /// each with an associated log probability.
    /// logprobs must be set to true if this parameter is used.
    #[prost(int32, optional, tag = "6")]
    pub top_logprobs: ::core::option::Option<i32>,
    /// An opaque string supplied by the API client (customer) to identify a user.
    /// The string will be stored in the logs and can be used in customer service
    /// requests to identify certain requests.
    #[prost(string, tag = "17")]
    pub user: ::prost::alloc::string::String,
}
/// Response of a text completion response sampling.
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct SampleTextResponse {
    /// The ID of this request. This ID will also show up on your billing records
    /// and you can use it when contacting us regarding a specific request.
    #[prost(string, tag = "1")]
    pub id: ::prost::alloc::string::String,
    /// Completions in response to the input messages. The number of completions is
    /// controlled via the `n` parameter on the request.
    #[prost(message, repeated, tag = "2")]
    pub choices: ::prost::alloc::vec::Vec<SampleChoice>,
    /// A UNIX timestamp (UTC) indicating when the response object was created.
    /// The timestamp is taken when the model starts generating response.
    #[prost(message, optional, tag = "5")]
    pub created: ::core::option::Option<::prost_wkt_types::Timestamp>,
    /// The name of the model used for the request. This model name contains
    /// the actual model name used rather than any aliases.
    /// This means the this can be `grok-2-1212` even when the request was
    /// specifying `grok-2-latest`.
    #[prost(string, tag = "6")]
    pub model: ::prost::alloc::string::String,
    /// Note supported yet. Included for compatibility reasons.
    #[prost(string, tag = "7")]
    pub system_fingerprint: ::prost::alloc::string::String,
    /// The number of tokens consumed by this request.
    #[prost(message, optional, tag = "9")]
    pub usage: ::core::option::Option<SamplingUsage>,
}
/// Contains the response generated by the model.
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct SampleChoice {
    /// Indicating why the model stopped sampling.
    #[prost(enumeration = "FinishReason", tag = "1")]
    pub finish_reason: i32,
    /// The index of this choice in the list of choices. If you set `n > 1` on
    /// your request, you will receive more than one choice in your response.
    #[prost(int32, tag = "2")]
    pub index: i32,
    /// The actual text generated by the model.
    #[prost(string, tag = "3")]
    pub text: ::prost::alloc::string::String,
}
/// Reasons why the model stopped sampling.
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration)]
#[repr(i32)]
pub enum FinishReason {
    /// Invalid reason.
    ReasonInvalid = 0,
    /// The max_len parameter specified on the input is reached.
    ReasonMaxLen = 1,
    /// The maximum context length of the model is reached.
    ReasonMaxContext = 2,
    /// One of the stop words was found.
    ReasonStop = 3,
    /// A tool call is included in the response.
    ReasonToolCalls = 4,
    /// Time limit has been reached.
    ReasonTimeLimit = 5,
}
impl FinishReason {
    /// String value of the enum field names used in the ProtoBuf definition.
    ///
    /// The values are not transformed in any way and thus are considered stable
    /// (if the ProtoBuf definition does not change) and safe for programmatic use.
    pub fn as_str_name(&self) -> &'static str {
        match self {
            Self::ReasonInvalid => "REASON_INVALID",
            Self::ReasonMaxLen => "REASON_MAX_LEN",
            Self::ReasonMaxContext => "REASON_MAX_CONTEXT",
            Self::ReasonStop => "REASON_STOP",
            Self::ReasonToolCalls => "REASON_TOOL_CALLS",
            Self::ReasonTimeLimit => "REASON_TIME_LIMIT",
        }
    }
    /// Creates an enum from field names used in the ProtoBuf definition.
    pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
        match value {
            "REASON_INVALID" => Some(Self::ReasonInvalid),
            "REASON_MAX_LEN" => Some(Self::ReasonMaxLen),
            "REASON_MAX_CONTEXT" => Some(Self::ReasonMaxContext),
            "REASON_STOP" => Some(Self::ReasonStop),
            "REASON_TOOL_CALLS" => Some(Self::ReasonToolCalls),
            "REASON_TIME_LIMIT" => Some(Self::ReasonTimeLimit),
            _ => None,
        }
    }
}
/// Generated client implementations.
pub mod sample_client {
    #![allow(
        unused_variables,
        dead_code,
        missing_docs,
        clippy::wildcard_imports,
        clippy::let_unit_value,
    )]
    use tonic::codegen::*;
    use tonic::codegen::http::Uri;
    /// An API service for sampling the responses of available language models.
    #[derive(Debug, Clone)]
    pub struct SampleClient<T> {
        inner: tonic::client::Grpc<T>,
    }
    impl SampleClient<tonic::transport::Channel> {
        /// Attempt to create a new client by connecting to a given endpoint.
        pub async fn connect<D>(dst: D) -> Result<Self, tonic::transport::Error>
        where
            D: TryInto<tonic::transport::Endpoint>,
            D::Error: Into<StdError>,
        {
            let conn = tonic::transport::Endpoint::new(dst)?.connect().await?;
            Ok(Self::new(conn))
        }
    }
    impl<T> SampleClient<T>
    where
        T: tonic::client::GrpcService<tonic::body::Body>,
        T::Error: Into<StdError>,
        T::ResponseBody: Body<Data = Bytes> + std::marker::Send + 'static,
        <T::ResponseBody as Body>::Error: Into<StdError> + std::marker::Send,
    {
        pub fn new(inner: T) -> Self {
            let inner = tonic::client::Grpc::new(inner);
            Self { inner }
        }
        pub fn with_origin(inner: T, origin: Uri) -> Self {
            let inner = tonic::client::Grpc::with_origin(inner, origin);
            Self { inner }
        }
        pub fn with_interceptor<F>(
            inner: T,
            interceptor: F,
        ) -> SampleClient<InterceptedService<T, F>>
        where
            F: tonic::service::Interceptor,
            T::ResponseBody: Default,
            T: tonic::codegen::Service<
                http::Request<tonic::body::Body>,
                Response = http::Response<
                    <T as tonic::client::GrpcService<tonic::body::Body>>::ResponseBody,
                >,
            >,
            <T as tonic::codegen::Service<
                http::Request<tonic::body::Body>,
            >>::Error: Into<StdError> + std::marker::Send + std::marker::Sync,
        {
            SampleClient::new(InterceptedService::new(inner, interceptor))
        }
        /// Compress requests with the given encoding.
        ///
        /// This requires the server to support it otherwise it might respond with an
        /// error.
        #[must_use]
        pub fn send_compressed(mut self, encoding: CompressionEncoding) -> Self {
            self.inner = self.inner.send_compressed(encoding);
            self
        }
        /// Enable decompressing responses.
        #[must_use]
        pub fn accept_compressed(mut self, encoding: CompressionEncoding) -> Self {
            self.inner = self.inner.accept_compressed(encoding);
            self
        }
        /// Limits the maximum size of a decoded message.
        ///
        /// Default: `4MB`
        #[must_use]
        pub fn max_decoding_message_size(mut self, limit: usize) -> Self {
            self.inner = self.inner.max_decoding_message_size(limit);
            self
        }
        /// Limits the maximum size of an encoded message.
        ///
        /// Default: `usize::MAX`
        #[must_use]
        pub fn max_encoding_message_size(mut self, limit: usize) -> Self {
            self.inner = self.inner.max_encoding_message_size(limit);
            self
        }
        /// Get raw sampling of text response from the model inference.
        pub async fn sample_text(
            &mut self,
            request: impl tonic::IntoRequest<super::SampleTextRequest>,
        ) -> std::result::Result<
            tonic::Response<super::SampleTextResponse>,
            tonic::Status,
        > {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::unknown(
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic_prost::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/xai_api.Sample/SampleText",
            );
            let mut req = request.into_request();
            req.extensions_mut().insert(GrpcMethod::new("xai_api.Sample", "SampleText"));
            self.inner.unary(req, path, codec).await
        }
        /// Get streaming raw sampling of text response from the model inference.
        pub async fn sample_text_streaming(
            &mut self,
            request: impl tonic::IntoRequest<super::SampleTextRequest>,
        ) -> std::result::Result<
            tonic::Response<tonic::codec::Streaming<super::SampleTextResponse>>,
            tonic::Status,
        > {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::unknown(
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic_prost::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/xai_api.Sample/SampleTextStreaming",
            );
            let mut req = request.into_request();
            req.extensions_mut()
                .insert(GrpcMethod::new("xai_api.Sample", "SampleTextStreaming"));
            self.inner.server_streaming(req, path, codec).await
        }
    }
}
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct GetCompletionsRequest {
    /// A sequence of messages in the conversation. There must be at least a single
    /// message that the model can respond to.
    #[prost(message, repeated, tag = "1")]
    pub messages: ::prost::alloc::vec::Vec<Message>,
    /// Name of the model. This is the name as reported by the models API. More
    /// details can be found on your console at <https://console.x.ai.>
    #[prost(string, tag = "2")]
    pub model: ::prost::alloc::string::String,
    /// An opaque string supplied by the API client (customer) to identify a user.
    /// The string will be stored in the logs and can be used in customer service
    /// requests to identify certain requests.
    #[prost(string, tag = "16")]
    pub user: ::prost::alloc::string::String,
    /// The number of completions to create concurrently. A single completion will
    /// be generated if the parameter is unset. Each completion is charged at the
    /// same rate. You can generate at most 128 concurrent completions.
    /// PLEASE NOTE: This field is deprecated and will be removed in the future.
    #[prost(int32, optional, tag = "8")]
    pub n: ::core::option::Option<i32>,
    /// The maximum number of tokens to sample. If unset, the model samples until
    /// one of the following stop-conditions is reached:
    ///
    /// * The context length of the model is exceeded
    /// * One of the `stop` sequences has been observed.
    /// * The time limit exceeds.
    ///
    /// Note that for reasoning models and models that support function calls, the
    /// limit is only applied to the main content and not to the reasoning content
    /// or function calls.
    ///
    /// We recommend choosing a reasonable value to reduce the risk of accidental
    /// long-generations that consume many tokens.
    #[prost(int32, optional, tag = "7")]
    pub max_tokens: ::core::option::Option<i32>,
    /// A random seed used to make the sampling process deterministic. This is
    /// provided in a best-effort basis without guarantee that sampling is 100%
    /// deterministic given a seed. This is primarily provided for short-lived
    /// testing purposes. Given a fixed request and seed, the answers may change
    /// over time as our systems evolve.
    #[prost(int32, optional, tag = "11")]
    pub seed: ::core::option::Option<i32>,
    /// String patterns that will cause the sampling procedure to stop prematurely
    /// when observed.
    /// Note that the completion is based on individual tokens and sampling can
    /// only terminate at token boundaries. If a stop string is a substring of an
    /// individual token, the completion will include the entire token, which
    /// extends beyond the stop string.
    /// For example, if `stop = \["wor"\]` and we prompt the model with "hello" to
    /// which it responds with "world", then the sampling procedure will stop after
    /// observing the "world" token and the completion will contain
    /// the entire world "world" even though the stop string was just "wor".
    /// You can provide at most 8 stop strings.
    #[prost(string, repeated, tag = "12")]
    pub stop: ::prost::alloc::vec::Vec<::prost::alloc::string::String>,
    /// A number between 0 and 2 used to control the variance of completions.
    /// The smaller the value, the more deterministic the model will become. For
    /// example, if we sample 1000 answers to the same prompt at a temperature of
    /// 0.001, then most of the 1000 answers will be identical. Conversely, if we
    /// conduct the same experiment at a temperature of 2, virtually no two answers
    /// will be identical. Note that increasing the temperature will cause
    /// the model to hallucinate more strongly.
    #[prost(float, optional, tag = "14")]
    pub temperature: ::core::option::Option<f32>,
    /// A number between 0 and 1 controlling the likelihood of the model to use
    /// less-common answers. Recall that the model produces a probability for
    /// each token. This means, for any choice of token there are thousands of
    /// possibilities to choose from. This parameter controls the "nucleus sampling
    /// algorithm". Instead of considering every possible token at every step, we
    /// only look at the K tokens who's probabilities exceed `top_p`.
    /// For example, if we set `top_p = 0.9`, then the set of tokens we actually
    /// sample from, will have a probability mass of at least 90%. In practice,
    /// low values will make the model more deterministic.
    #[prost(float, optional, tag = "15")]
    pub top_p: ::core::option::Option<f32>,
    /// If set to true, log probabilities of the sampling are returned.
    #[prost(bool, tag = "5")]
    pub logprobs: bool,
    /// Number of top log probabilities to return.
    #[prost(int32, optional, tag = "6")]
    pub top_logprobs: ::core::option::Option<i32>,
    /// A list of tools the model may call. Currently, only functions are supported
    /// as a tool. Use this to provide a list of functions the model may generate
    /// JSON inputs for.
    #[prost(message, repeated, tag = "17")]
    pub tools: ::prost::alloc::vec::Vec<Tool>,
    /// Controls if the model can, should, or must not use tools.
    #[prost(message, optional, tag = "18")]
    pub tool_choice: ::core::option::Option<ToolChoice>,
    /// Formatting constraint on the response.
    #[prost(message, optional, tag = "10")]
    pub response_format: ::core::option::Option<ResponseFormat>,
    /// Positive values penalize new tokens based on their existing frequency in
    /// the text so far, decreasing the model's likelihood to repeat the same line
    /// verbatim.
    #[prost(float, optional, tag = "3")]
    pub frequency_penalty: ::core::option::Option<f32>,
    /// Positive values penalize new tokens based on whether they appear in
    /// the text so far, increasing the model's likelihood to talk about
    /// new topics.
    #[prost(float, optional, tag = "9")]
    pub presence_penalty: ::core::option::Option<f32>,
    /// Constrains effort on reasoning for reasoning models. Default to `EFFORT_MEDIUM`.
    #[prost(enumeration = "ReasoningEffort", optional, tag = "19")]
    pub reasoning_effort: ::core::option::Option<i32>,
    /// Set the parameters to be used for realtime data. If not set, no realtime data will be acquired by the model.
    #[prost(message, optional, tag = "20")]
    pub search_parameters: ::core::option::Option<SearchParameters>,
    /// / If set to false, the model can perform maximum one tool call per response. Default to true.
    #[prost(bool, optional, tag = "21")]
    pub parallel_tool_calls: ::core::option::Option<bool>,
    /// Previous response id. The messages from this response must be chained.
    #[prost(string, optional, tag = "22")]
    pub previous_response_id: ::core::option::Option<::prost::alloc::string::String>,
    /// Whether to store request and responses. Default is false.
    #[prost(bool, tag = "23")]
    pub store_messages: bool,
    /// Whether to use encrypted thinking for thinking trace rehydration.
    #[prost(bool, tag = "24")]
    pub use_encrypted_content: bool,
    /// Maximum number of agentic tool calling turns allowed for this request.
    /// If not set, defaults to the server's global cap.
    /// The effective max_turns will be the min of the server's global cap and the request's max_turns.
    /// This parameter will be ignored for any non-agentic requests.
    /// With parallel tool calls, multiple tool calls can occur within a single turn,
    /// so max_turns does not necessarily equal the total number of tool calls.
    #[prost(int32, optional, tag = "25")]
    pub max_turns: ::core::option::Option<i32>,
    /// Allow the users to control what optional fields to be returned in the response.
    #[prost(enumeration = "IncludeOption", repeated, tag = "26")]
    pub include: ::prost::alloc::vec::Vec<i32>,
}
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct GetChatCompletionResponse {
    /// The ID of this request. This ID will also show up on your billing records
    /// and you can use it when contacting us regarding a specific request.
    #[prost(string, tag = "1")]
    pub id: ::prost::alloc::string::String,
    /// Model-generated outputs/responses to the input messages. Each output contains
    /// the model's response including text content, reasoning traces, tool calls, and
    /// metadata about the generation process.
    #[prost(message, repeated, tag = "2")]
    pub outputs: ::prost::alloc::vec::Vec<CompletionOutput>,
    /// A UNIX timestamp (UTC) indicating when the response object was created.
    /// The timestamp is taken when the model starts generating response.
    #[prost(message, optional, tag = "5")]
    pub created: ::core::option::Option<::prost_wkt_types::Timestamp>,
    /// The name of the model used for the request. This model name contains
    /// the actual model name used rather than any aliases.
    /// This means the this can be `grok-2-1212` even when the request was
    /// specifying `grok-2-latest`.
    #[prost(string, tag = "6")]
    pub model: ::prost::alloc::string::String,
    /// This fingerprint represents the backend configuration that the model runs
    /// with.
    #[prost(string, tag = "7")]
    pub system_fingerprint: ::prost::alloc::string::String,
    /// The number of tokens consumed by this request.
    #[prost(message, optional, tag = "9")]
    pub usage: ::core::option::Option<SamplingUsage>,
    /// / List of all the external pages (urls) used by the model to produce its final answer.
    /// This is only present when live search is enabled, (That is `SearchParameters` have been defined in `GetCompletionsRequest`).
    #[prost(string, repeated, tag = "10")]
    pub citations: ::prost::alloc::vec::Vec<::prost::alloc::string::String>,
    /// Settings used while generating the response.
    #[prost(message, optional, tag = "11")]
    pub settings: ::core::option::Option<RequestSettings>,
    /// Debug output. Only available to trusted testers.
    #[prost(message, optional, tag = "12")]
    pub debug_output: ::core::option::Option<DebugOutput>,
}
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct GetChatCompletionChunk {
    /// The ID of this request. This ID will also show up on your billing records
    /// and you can use it when contacting us regarding a specific request.
    #[prost(string, tag = "1")]
    pub id: ::prost::alloc::string::String,
    /// Model-generated outputs/responses being streamed as they are generated.
    /// Each output chunk contains incremental updates to the model's response.
    #[prost(message, repeated, tag = "2")]
    pub outputs: ::prost::alloc::vec::Vec<CompletionOutputChunk>,
    /// A UNIX timestamp (UTC) indicating when the response object was created.
    /// The timestamp is taken when the model starts generating response.
    #[prost(message, optional, tag = "3")]
    pub created: ::core::option::Option<::prost_wkt_types::Timestamp>,
    /// The name of the model used for the request. This model name contains
    /// the actual model name used rather than any aliases.
    /// This means the this can be `grok-2-1212` even when the request was
    /// specifying `grok-2-latest`.
    #[prost(string, tag = "4")]
    pub model: ::prost::alloc::string::String,
    /// This fingerprint represents the backend configuration that the model runs
    /// with.
    #[prost(string, tag = "5")]
    pub system_fingerprint: ::prost::alloc::string::String,
    /// The total number of tokens consumed when this chunk was streamed. Note that
    /// this is not the final number of tokens billed unless this is the last chunk
    /// in the stream.
    #[prost(message, optional, tag = "6")]
    pub usage: ::core::option::Option<SamplingUsage>,
    /// / List of all the external pages used by the model to answer. Only populated for the last chunk.
    /// This is only present for requests that make use of live search or server-side search tools.
    #[prost(string, repeated, tag = "7")]
    pub citations: ::prost::alloc::vec::Vec<::prost::alloc::string::String>,
    /// Only available for teams that have debugging privileges.
    #[prost(message, optional, tag = "10")]
    pub debug_output: ::core::option::Option<DebugOutput>,
}
/// Response from GetDeferredCompletion, including the response if the completion
/// request has been processed without error.
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct GetDeferredCompletionResponse {
    /// Current status of the request.
    #[prost(enumeration = "DeferredStatus", tag = "2")]
    pub status: i32,
    /// Response. Only present if `status=DONE`
    #[prost(message, optional, tag = "1")]
    pub response: ::core::option::Option<GetChatCompletionResponse>,
}
/// Contains the response generated by the model.
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct CompletionOutput {
    /// Indicating why the model stopped sampling.
    #[prost(enumeration = "FinishReason", tag = "1")]
    pub finish_reason: i32,
    /// The index of this output in the list of outputs. When multiple outputs are
    /// generated, each output is assigned a sequential index starting from 0.
    #[prost(int32, tag = "2")]
    pub index: i32,
    /// The actual message generated by the model.
    #[prost(message, optional, tag = "3")]
    pub message: ::core::option::Option<CompletionMessage>,
    /// The log probabilities of the sampling.
    #[prost(message, optional, tag = "4")]
    pub logprobs: ::core::option::Option<LogProbs>,
}
/// Holds the model output (i.e. the result of the sampling process).
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct CompletionMessage {
    /// The generated text based on the input prompt.
    #[prost(string, tag = "1")]
    pub content: ::prost::alloc::string::String,
    /// Reasoning trace the model produced before issuing the final answer.
    #[prost(string, tag = "4")]
    pub reasoning_content: ::prost::alloc::string::String,
    /// The role of the message author. Will always default to "assistant".
    #[prost(enumeration = "MessageRole", tag = "2")]
    pub role: i32,
    /// The tools that the assistant wants to call.
    #[prost(message, repeated, tag = "3")]
    pub tool_calls: ::prost::alloc::vec::Vec<ToolCall>,
    /// The encrypted content.
    #[prost(string, tag = "5")]
    pub encrypted_content: ::prost::alloc::string::String,
    /// The citations that the model used to answer the question.
    #[prost(message, repeated, tag = "6")]
    pub citations: ::prost::alloc::vec::Vec<InlineCitation>,
}
/// Holds the differences (deltas) that when concatenated make up the entire
/// agent response.
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct CompletionOutputChunk {
    /// The actual text differences that need to be accumulated on the client.
    #[prost(message, optional, tag = "1")]
    pub delta: ::core::option::Option<Delta>,
    /// The log probability of the choice.
    #[prost(message, optional, tag = "2")]
    pub logprobs: ::core::option::Option<LogProbs>,
    /// Indicating why the model stopped sampling.
    #[prost(enumeration = "FinishReason", tag = "3")]
    pub finish_reason: i32,
    /// The index of this output chunk in the list of output chunks.
    #[prost(int32, tag = "4")]
    pub index: i32,
}
/// The delta of a streaming response.
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct Delta {
    /// The main model output/answer.
    #[prost(string, tag = "1")]
    pub content: ::prost::alloc::string::String,
    /// Part of the model's reasoning trace.
    #[prost(string, tag = "4")]
    pub reasoning_content: ::prost::alloc::string::String,
    /// The entity type who sent the message. For example, a message can be sent by
    /// a user or the assistant.
    #[prost(enumeration = "MessageRole", tag = "2")]
    pub role: i32,
    /// A list of tool calls if tool call is requested by the model.
    #[prost(message, repeated, tag = "3")]
    pub tool_calls: ::prost::alloc::vec::Vec<ToolCall>,
    /// The encrypted content.
    #[prost(string, tag = "5")]
    pub encrypted_content: ::prost::alloc::string::String,
    /// The citations that the model used to answer the question.
    #[prost(message, repeated, tag = "6")]
    pub citations: ::prost::alloc::vec::Vec<InlineCitation>,
}
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct InlineCitation {
    /// The display number for this citation (e.g., "1", "2", "3").
    /// This ID is reused when the same source is cited multiple times in a
    /// response, ensuring consistent numbering (e.g., the same URL always shows as
    /// \[1\]).
    #[prost(string, tag = "1")]
    pub id: ::prost::alloc::string::String,
    /// The character position in the response text where the citation markdown
    /// link begins. This is the index of the first '\[' character in the citation
    /// format [id](id)(url). Uses inclusive indexing (the character at this index is
    /// part of the citation).
    #[prost(int32, tag = "2")]
    pub start_index: i32,
    /// The character position in the response text immediately after the citation
    /// markdown link ends. This is the index after the final '\]' character in the
    /// citation format [id](id)(url). Uses exclusive indexing (the character at this
    /// index is NOT part of the citation). Together with start_index,
    /// text\[start_index:end_index\] extracts the full citation link.
    #[prost(int32, tag = "6")]
    pub end_index: i32,
    /// The citation type.
    #[prost(oneof = "inline_citation::Citation", tags = "3, 4, 5")]
    pub citation: ::core::option::Option<inline_citation::Citation>,
}
/// Nested message and enum types in `InlineCitation`.
pub mod inline_citation {
    /// The citation type.
    #[derive(serde::Serialize, serde::Deserialize)]
    #[derive(Clone, PartialEq, ::prost::Oneof)]
    pub enum Citation {
        /// The citation returned from the web search tool.
        #[prost(message, tag = "3")]
        WebCitation(super::WebCitation),
        /// The citation returned from the X search tool.
        #[prost(message, tag = "4")]
        XCitation(super::XCitation),
        /// The citation returned from the collections search tool.
        #[prost(message, tag = "5")]
        CollectionsCitation(super::CollectionsCitation),
    }
}
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct WebCitation {
    /// The url of the web page that the citation is from.
    #[prost(string, tag = "1")]
    pub url: ::prost::alloc::string::String,
}
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct XCitation {
    /// The url of the X post or profile that the citation is from.
    /// The url is always a x.com url.
    #[prost(string, tag = "1")]
    pub url: ::prost::alloc::string::String,
}
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct CollectionsCitation {
    /// The id of the file that the citation is from.
    #[prost(string, tag = "1")]
    pub file_id: ::prost::alloc::string::String,
    /// The id of the chunk that the citation is from.
    #[prost(string, tag = "2")]
    pub chunk_id: ::prost::alloc::string::String,
    /// The content of the chunk that the citation is from.
    #[prost(string, tag = "3")]
    pub chunk_content: ::prost::alloc::string::String,
    /// The relevance score of the citation.
    #[prost(float, tag = "4")]
    pub score: f32,
    /// The ids of the collections that the citation is from.
    #[prost(string, repeated, tag = "5")]
    pub collection_ids: ::prost::alloc::vec::Vec<::prost::alloc::string::String>,
}
/// Holding the log probabilities of the sampling.
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct LogProbs {
    /// A list of log probability entries, each corresponding to a sampled token
    /// and its associated data.
    #[prost(message, repeated, tag = "1")]
    pub content: ::prost::alloc::vec::Vec<LogProb>,
}
/// Represents the logarithmic probability and metadata for a single sampled
/// token.
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct LogProb {
    /// The text representation of the sampled token.
    #[prost(string, tag = "1")]
    pub token: ::prost::alloc::string::String,
    /// The logarithmic probability of this token being sampled, given the prior
    /// context.
    #[prost(float, tag = "2")]
    pub logprob: f32,
    /// The raw byte representation of the token, useful for handling non-text or
    /// encoded data.
    #[prost(bytes = "vec", tag = "3")]
    pub bytes: ::prost::alloc::vec::Vec<u8>,
    /// A list of the top alternative tokens and their log probabilities at this
    /// sampling step.
    #[prost(message, repeated, tag = "4")]
    pub top_logprobs: ::prost::alloc::vec::Vec<TopLogProb>,
}
/// Represents an alternative token and its log probability among the top
/// candidates.
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct TopLogProb {
    /// The text representation of an alternative token considered by the model.
    #[prost(string, tag = "1")]
    pub token: ::prost::alloc::string::String,
    /// The logarithmic probability of this alternative token being sampled.
    #[prost(float, tag = "2")]
    pub logprob: f32,
    /// The raw byte representation of the alternative token.
    #[prost(bytes = "vec", tag = "3")]
    pub bytes: ::prost::alloc::vec::Vec<u8>,
}
/// Holds a single content element that is part of an input message.
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct Content {
    #[prost(oneof = "content::Content", tags = "1, 2, 3")]
    pub content: ::core::option::Option<content::Content>,
}
/// Nested message and enum types in `Content`.
pub mod content {
    #[derive(serde::Serialize, serde::Deserialize)]
    #[derive(Clone, PartialEq, Eq, Hash, ::prost::Oneof)]
    pub enum Content {
        /// The content is a pure text message.
        #[prost(string, tag = "1")]
        Text(::prost::alloc::string::String),
        /// The content is a single image.
        #[prost(message, tag = "2")]
        ImageUrl(super::ImageUrlContent),
        /// The content is a file attachment (PDF, document, etc.).
        #[prost(message, tag = "3")]
        File(super::FileContent),
    }
}
/// A file attachment in a message.
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct FileContent {
    /// The file ID returned by the Files API when a user uploads a file.
    /// This ID is used to reference the uploaded file in chat conversations.
    #[prost(string, tag = "1")]
    pub file_id: ::prost::alloc::string::String,
}
/// A message in a conversation. This message is part of the model input. Each
/// message originates from a "role", which indicates the entity type who sent
/// the message. Messages can contain multiple content elements such as text and
/// images.
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct Message {
    /// The content of the message. Some model support multi-modal message contents
    /// that consist of text and images. At least one content element must be set
    /// for each message.
    #[prost(message, repeated, tag = "1")]
    pub content: ::prost::alloc::vec::Vec<Content>,
    /// Reasoning trace the model produced before issuing the final answer.
    #[prost(string, optional, tag = "5")]
    pub reasoning_content: ::core::option::Option<::prost::alloc::string::String>,
    /// The entity type who sent the message. For example, a message can be sent by
    /// a user or the assistant.
    #[prost(enumeration = "MessageRole", tag = "2")]
    pub role: i32,
    /// The name of the entity who sent the message. The name can only be set if
    /// the role is ROLE_USER.
    #[prost(string, tag = "3")]
    pub name: ::prost::alloc::string::String,
    /// The tools that the assistant wants to call.
    #[prost(message, repeated, tag = "4")]
    pub tool_calls: ::prost::alloc::vec::Vec<ToolCall>,
    /// The encrypted content.
    #[prost(string, tag = "6")]
    pub encrypted_content: ::prost::alloc::string::String,
}
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct ToolChoice {
    #[prost(oneof = "tool_choice::ToolChoice", tags = "1, 2")]
    pub tool_choice: ::core::option::Option<tool_choice::ToolChoice>,
}
/// Nested message and enum types in `ToolChoice`.
pub mod tool_choice {
    #[derive(serde::Serialize, serde::Deserialize)]
    #[derive(Clone, PartialEq, Eq, Hash, ::prost::Oneof)]
    pub enum ToolChoice {
        /// Force the model to perform in a given mode.
        #[prost(enumeration = "super::ToolMode", tag = "1")]
        Mode(i32),
        /// Force the model to call a particular function.
        #[prost(string, tag = "2")]
        FunctionName(::prost::alloc::string::String),
    }
}
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct Tool {
    #[prost(oneof = "tool::Tool", tags = "1, 3, 4, 5, 6, 7, 8")]
    pub tool: ::core::option::Option<tool::Tool>,
}
/// Nested message and enum types in `Tool`.
pub mod tool {
    #[derive(serde::Serialize, serde::Deserialize)]
    #[derive(Clone, PartialEq, ::prost::Oneof)]
    pub enum Tool {
        /// Tool Call defined by user
        #[prost(message, tag = "1")]
        Function(super::Function),
        /// Built in web search.
        #[prost(message, tag = "3")]
        WebSearch(super::WebSearch),
        /// Built in X search.
        #[prost(message, tag = "4")]
        XSearch(super::XSearch),
        /// Built in code execution.
        #[prost(message, tag = "5")]
        CodeExecution(super::CodeExecution),
        /// Built in collections search.
        #[prost(message, tag = "6")]
        CollectionsSearch(super::CollectionsSearch),
        /// A remote MCP server to use.
        #[prost(message, tag = "7")]
        Mcp(super::Mcp),
        /// Built in attachment search.
        #[prost(message, tag = "8")]
        AttachmentSearch(super::AttachmentSearch),
    }
}
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct Mcp {
    /// A label for the server. if provided, this will be used to prefix tool calls.
    #[prost(string, tag = "1")]
    pub server_label: ::prost::alloc::string::String,
    /// A description of the server.
    #[prost(string, tag = "2")]
    pub server_description: ::prost::alloc::string::String,
    /// The URL of the MCP server.
    #[prost(string, tag = "3")]
    pub server_url: ::prost::alloc::string::String,
    /// A list of tool names that are allowed to be called by the model. If empty, all tools are allowed.
    #[prost(string, repeated, tag = "4")]
    pub allowed_tool_names: ::prost::alloc::vec::Vec<::prost::alloc::string::String>,
    /// An optional authorization token to use when calling the MCP server. This will be set as the Authorization header.
    #[prost(string, optional, tag = "5")]
    pub authorization: ::core::option::Option<::prost::alloc::string::String>,
    /// Extra headers that will be included in the request to the MCP server.
    #[prost(map = "string, string", tag = "6")]
    pub extra_headers: ::std::collections::HashMap<
        ::prost::alloc::string::String,
        ::prost::alloc::string::String,
    >,
}
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct WebSearch {
    /// List of website domains (without protocol specification or subdomains) to exclude from search results (e.g., \["example.com"\]).
    /// Use this to prevent results from unwanted sites. A maximum of 5 websites can be excluded.
    /// This parameter cannot be set together with `allowed_domains`.
    #[prost(string, repeated, tag = "1")]
    pub excluded_domains: ::prost::alloc::vec::Vec<::prost::alloc::string::String>,
    /// List of website domains (without protocol specification or subdomains)
    /// to restrict search results to (e.g., \["example.com"\]). A maximum of 5 websites can be allowed.
    /// Use this as a whitelist to limit results to only these specific sites; no other websites will
    /// be considered. If no relevant information is found on these websites, the number of results
    /// returned might be smaller than `max_search_results` set in `SearchParameters`. Note: This
    /// parameter cannot be set together with `excluded_domains`.
    #[prost(string, repeated, tag = "2")]
    pub allowed_domains: ::prost::alloc::vec::Vec<::prost::alloc::string::String>,
    /// Enable image understanding in downstream tools (e.g. allow fetching and interpreting images).
    /// When true, the server may add image viewing tools to the active MCP toolset.
    #[prost(bool, optional, tag = "3")]
    pub enable_image_understanding: ::core::option::Option<bool>,
}
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct XSearch {
    /// Optional start date for search results in ISO-8601 YYYY-MM-DD format (e.g., "2024-05-24").
    /// Only content after this date will be considered. Defaults to unset (no start date restriction).
    /// See <https://en.wikipedia.org/wiki/ISO_8601> for format details.
    #[prost(message, optional, tag = "1")]
    pub from_date: ::core::option::Option<::prost_wkt_types::Timestamp>,
    /// Optional end date for search results in ISO-8601 YYYY-MM-DD format (e.g., "2024-12-24").
    /// Only content before this date will be considered. Defaults to unset (no end date restriction).
    /// See <https://en.wikipedia.org/wiki/ISO_8601> for format details.
    #[prost(message, optional, tag = "2")]
    pub to_date: ::core::option::Option<::prost_wkt_types::Timestamp>,
    /// Optional list of X usernames (without the '@' symbol) to limit search results to posts
    /// from specific accounts (e.g., \["xai"\]). If set, only posts authored by these
    /// handles will be considered in the agentic search.
    /// This field can not be set together with `excluded_x_handles`.
    /// Defaults to unset (no exclusions).
    #[prost(string, repeated, tag = "3")]
    pub allowed_x_handles: ::prost::alloc::vec::Vec<::prost::alloc::string::String>,
    /// Optional list of X usernames (without the '@' symbol) used to exclude posts from specific accounts.
    /// If set, posts authored by these handles will be excluded from the agentic search results.
    /// This field can not be set together with `allowed_x_handles`.
    /// Defaults to unset (no exclusions).
    #[prost(string, repeated, tag = "4")]
    pub excluded_x_handles: ::prost::alloc::vec::Vec<::prost::alloc::string::String>,
    /// Enable image understanding in downstream tools (e.g. allow fetching and interpreting images).
    /// When true, the server may add image viewing tools to the active MCP toolset.
    #[prost(bool, optional, tag = "5")]
    pub enable_image_understanding: ::core::option::Option<bool>,
    /// Enable video understanding in downstream tools (e.g. allow fetching and interpreting videos).
    /// When true, the server may add video viewing tools to the active MCP toolset.
    #[prost(bool, optional, tag = "6")]
    pub enable_video_understanding: ::core::option::Option<bool>,
}
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, Copy, PartialEq, Eq, Hash, ::prost::Message)]
pub struct CodeExecution {}
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct CollectionsSearch {
    /// The ID(s) of the source collection(s) within which the search should be performed.
    /// A maximum of 10 collections IDs can be used for search.
    #[prost(string, repeated, tag = "1")]
    pub collection_ids: ::prost::alloc::vec::Vec<::prost::alloc::string::String>,
    /// Optional number of chunks to be returned for each collections search.
    /// Defaults to 10.
    #[prost(int32, optional, tag = "2")]
    pub limit: ::core::option::Option<i32>,
    /// User-defined instructions to be included in the search query. Defaults to generic search
    /// instructions used by the collections search backend if unset.
    #[prost(string, optional, tag = "3")]
    pub instructions: ::core::option::Option<::prost::alloc::string::String>,
    /// How to perform the document search. Defaults to hybrid retrieval when unset.
    #[prost(oneof = "collections_search::RetrievalMode", tags = "4, 5, 6")]
    pub retrieval_mode: ::core::option::Option<collections_search::RetrievalMode>,
}
/// Nested message and enum types in `CollectionsSearch`.
pub mod collections_search {
    /// How to perform the document search. Defaults to hybrid retrieval when unset.
    #[derive(serde::Serialize, serde::Deserialize)]
    #[derive(Clone, PartialEq, ::prost::Oneof)]
    pub enum RetrievalMode {
        /// Perform hybrid retrieval combining keyword and semantic search.
        #[prost(message, tag = "4")]
        HybridRetrieval(super::HybridRetrieval),
        /// Perform pure semantic retrieval using dense embeddings.
        #[prost(message, tag = "5")]
        SemanticRetrieval(super::SemanticRetrieval),
        /// Perform keyword-based retrieval using sparse embeddings.
        #[prost(message, tag = "6")]
        KeywordRetrieval(super::KeywordRetrieval),
    }
}
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, Copy, PartialEq, Eq, Hash, ::prost::Message)]
pub struct AttachmentSearch {
    /// Optional number of files to limit the search to.
    #[prost(int32, optional, tag = "2")]
    pub limit: ::core::option::Option<i32>,
}
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct Function {
    /// Name of the function.
    #[prost(string, tag = "1")]
    pub name: ::prost::alloc::string::String,
    /// Description of the function.
    #[prost(string, tag = "2")]
    pub description: ::prost::alloc::string::String,
    /// Not supported: Only kept for compatibility reasons.
    #[prost(bool, tag = "3")]
    pub strict: bool,
    /// The parameters the functions accepts, described as a JSON Schema object.
    #[prost(string, tag = "4")]
    pub parameters: ::prost::alloc::string::String,
}
/// Content of a tool call, typically in a response from model.
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct ToolCall {
    /// The ID of the tool call.
    #[prost(string, tag = "1")]
    pub id: ::prost::alloc::string::String,
    /// Information to indicate whether the tool call needs to be executed on client side or server side.
    /// By default, it will be a client-side tool call if not specified.
    #[prost(enumeration = "ToolCallType", tag = "2")]
    pub r#type: i32,
    /// Status of the tool call.
    #[prost(enumeration = "ToolCallStatus", tag = "3")]
    pub status: i32,
    /// Error message if the tool call is failed.
    #[prost(string, optional, tag = "4")]
    pub error_message: ::core::option::Option<::prost::alloc::string::String>,
    /// Information regarding invoking the tool call.
    #[prost(oneof = "tool_call::Tool", tags = "10")]
    pub tool: ::core::option::Option<tool_call::Tool>,
}
/// Nested message and enum types in `ToolCall`.
pub mod tool_call {
    /// Information regarding invoking the tool call.
    #[derive(serde::Serialize, serde::Deserialize)]
    #[derive(Clone, PartialEq, Eq, Hash, ::prost::Oneof)]
    pub enum Tool {
        #[prost(message, tag = "10")]
        Function(super::FunctionCall),
    }
}
/// Tool call information.
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct FunctionCall {
    /// Name of the function to call.
    #[prost(string, tag = "1")]
    pub name: ::prost::alloc::string::String,
    /// Arguments used to call the function as json string.
    #[prost(string, tag = "2")]
    pub arguments: ::prost::alloc::string::String,
}
/// The response format for structured response.
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct ResponseFormat {
    /// Type of format expected for the response. Default to `FORMAT_TYPE_TEXT`
    #[prost(enumeration = "FormatType", tag = "1")]
    pub format_type: i32,
    /// The JSON schema that the response should conform to.
    /// Only considered if `format_type` is `FORMAT_TYPE_JSON_SCHEMA`.
    #[prost(string, optional, tag = "2")]
    pub schema: ::core::option::Option<::prost::alloc::string::String>,
}
/// Parameters for configuring search behavior in a chat request.
///
/// This message allows customization of search functionality when using models that support
/// searching external sources for information. You can specify which sources to search,
/// set date ranges for relevant content, control the search mode, and configure how
/// results are returned.
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct SearchParameters {
    /// Controls when search is performed. Possible values are:
    ///
    /// * OFF_SEARCH_MODE (default): No search is performed, and no external data will be considered.
    /// * ON_SEARCH_MODE: Search is always performed when sampling from the model and the model will search in every source provided for relevant data.
    /// * AUTO_SEARCH_MODE: The model decides whether to perform a search based on the prompt and which sources to use.
    #[prost(enumeration = "SearchMode", tag = "1")]
    pub mode: i32,
    /// A list of search sources to query, such as web, news, X, or RSS feeds.
    /// Multiple sources can be specified. If no sources are provided, the model will default to
    /// searching the web and X.
    #[prost(message, repeated, tag = "9")]
    pub sources: ::prost::alloc::vec::Vec<Source>,
    /// Optional start date for search results in ISO-8601 YYYY-MM-DD format (e.g., "2024-05-24").
    /// Only content after this date will be considered. Defaults to unset (no start date restriction).
    /// See <https://en.wikipedia.org/wiki/ISO_8601> for format details.
    #[prost(message, optional, tag = "4")]
    pub from_date: ::core::option::Option<::prost_wkt_types::Timestamp>,
    /// Optional end date for search results in ISO-8601 YYYY-MM-DD format (e.g., "2024-12-24").
    /// Only content before this date will be considered. Defaults to unset (no end date restriction).
    /// See <https://en.wikipedia.org/wiki/ISO_8601> for format details.
    #[prost(message, optional, tag = "5")]
    pub to_date: ::core::option::Option<::prost_wkt_types::Timestamp>,
    /// If set to true, the model will return a list of citations (URLs or references)
    /// to the sources used in generating the response. Defaults to true.
    #[prost(bool, tag = "7")]
    pub return_citations: bool,
    /// Optional limit on the number of search results to consider
    /// when generating a response. Must be in the range \[1, 30\]. Defaults to 15.
    #[prost(int32, optional, tag = "8")]
    pub max_search_results: ::core::option::Option<i32>,
}
/// Defines a source for search requests, specifying the type of content to search.
/// This message acts as a container for different types of search sources. Only one type
/// of source can be specified per instance using the oneof field.
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct Source {
    #[prost(oneof = "source::Source", tags = "1, 2, 3, 4")]
    pub source: ::core::option::Option<source::Source>,
}
/// Nested message and enum types in `Source`.
pub mod source {
    #[derive(serde::Serialize, serde::Deserialize)]
    #[derive(Clone, PartialEq, Eq, Hash, ::prost::Oneof)]
    pub enum Source {
        /// Configuration for searching online web content. Use this to search general websites
        /// with options to filter by country, exclude specific domains, or only allow specific domains.
        #[prost(message, tag = "1")]
        Web(super::WebSource),
        /// Configuration for searching recent articles and reports from news outlets.
        /// Useful for current events or topic-specific updates.
        #[prost(message, tag = "2")]
        News(super::NewsSource),
        /// Configuration for searching content on X. Allows focusing on
        /// specific user handles for targeted content.
        #[prost(message, tag = "3")]
        X(super::XSource),
        /// Configuration for searching content from RSS feeds. Requires specific feed URLs
        /// to query.
        #[prost(message, tag = "4")]
        Rss(super::RssSource),
    }
}
/// Configuration for a web search source in search requests.
///
/// This message configures a source for searching online web content. It allows specification
/// of regional content through country codes and filtering of results by excluding or allowing
/// specific websites.
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct WebSource {
    /// List of website domains (without protocol specification or subdomains) to exclude from search results (e.g., \["example.com"\]).
    /// Use this to prevent results from unwanted sites. A maximum of 5 websites can be excluded.
    /// This parameter cannot be set together with `allowed_websites`.
    #[prost(string, repeated, tag = "2")]
    pub excluded_websites: ::prost::alloc::vec::Vec<::prost::alloc::string::String>,
    /// List of website domains (without protocol specification or subdomains)
    /// to restrict search results to (e.g., \["example.com"\]). A maximum of 5 websites can be allowed.
    /// Use this as a whitelist to limit results to only these specific sites; no other websites will
    /// be considered. If no relevant information is found on these websites, the number of results
    /// returned might be smaller than `max_search_results` set in `SearchParameters`. Note: This
    /// parameter cannot be set together with `excluded_websites`.
    #[prost(string, repeated, tag = "5")]
    pub allowed_websites: ::prost::alloc::vec::Vec<::prost::alloc::string::String>,
    /// Optional ISO alpha-2 country code (e.g., "BE" for Belgium) to limit search results
    /// to content from a specific region or country. Defaults to unset (global search).
    /// See <https://en.wikipedia.org/wiki/ISO_3166-2> for valid codes.
    #[prost(string, optional, tag = "3")]
    pub country: ::core::option::Option<::prost::alloc::string::String>,
    /// Whether to exclude adult content from the search results. Defaults to true.
    #[prost(bool, tag = "4")]
    pub safe_search: bool,
}
/// Configuration for a news search source in search requests.
///
/// This message configures a source for searching recent articles and reports from news outlets.
/// It is useful for obtaining current events or topic-specific updates with regional filtering.
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct NewsSource {
    /// List of website domains (without protocol specification or subdomains)
    /// to exclude from search results (e.g., \["example.com"\]). A maximum of 5 websites can be excluded.
    /// Use this to prevent results from specific news sites. Defaults to unset (no exclusions).
    #[prost(string, repeated, tag = "2")]
    pub excluded_websites: ::prost::alloc::vec::Vec<::prost::alloc::string::String>,
    /// Optional ISO alpha-2 country code (e.g., "BE" for Belgium) to limit search results
    /// to news from a specific region or country. Defaults to unset (global news).
    /// See <https://en.wikipedia.org/wiki/ISO_3166-2> for valid codes.
    #[prost(string, optional, tag = "3")]
    pub country: ::core::option::Option<::prost::alloc::string::String>,
    /// Whether to exclude adult content from the search results. Defaults to true.
    #[prost(bool, tag = "4")]
    pub safe_search: bool,
}
/// Configuration for an X (formerly Twitter) search source in search requests.
///
/// This message configures a source for searching content on X. It allows focusing the search
/// on specific user handles to retrieve targeted posts and interactions.
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct XSource {
    /// Optional list of X usernames (without the '@' symbol) to limit search results to posts
    /// from specific accounts (e.g., \["xai"\]). If set, only posts authored by these
    /// handles will be considered in the live search.
    /// This field can not be set together with `excluded_x_handles`.
    /// Defaults to unset (no exclusions).
    #[prost(string, repeated, tag = "7")]
    pub included_x_handles: ::prost::alloc::vec::Vec<::prost::alloc::string::String>,
    /// Optional list of X usernames (without the '@' symbol) used to exclude posts from specific accounts.
    /// If set, posts authored by these handles will be excluded from the live search results.
    /// This field can not be set together with `included_x_handles`.
    /// Defaults to unset (no exclusions).
    #[prost(string, repeated, tag = "8")]
    pub excluded_x_handles: ::prost::alloc::vec::Vec<::prost::alloc::string::String>,
    /// Optional post favorite count threshold. Defaults to unset (don't filter posts by post favorite count).
    /// If set, only posts with a favorite count greater than or equal to this threshold will be considered.
    #[prost(int32, optional, tag = "9")]
    pub post_favorite_count: ::core::option::Option<i32>,
    /// Optional post view count threshold. Defaults to unset (don't filter posts by post view count).
    /// If set, only posts with a view count greater than or equal to this threshold will be considered.
    #[prost(int32, optional, tag = "10")]
    pub post_view_count: ::core::option::Option<i32>,
}
/// Configuration for an RSS search source in search requests.
///
/// This message configures a source for searching content from RSS feeds. It requires specific
/// feed URLs to query for content updates.
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct RssSource {
    /// List of RSS feed URLs to search. Each URL must point to a valid RSS feed.
    /// At least one link must be provided.
    #[prost(string, repeated, tag = "1")]
    pub links: ::prost::alloc::vec::Vec<::prost::alloc::string::String>,
}
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct RequestSettings {
    /// Max number of tokens that can be generated in a response. This includes both output and reasoning tokens.
    #[prost(int32, optional, tag = "1")]
    pub max_tokens: ::core::option::Option<i32>,
    /// / If set to false, the model can perform maximum one tool call. Default to true.
    #[prost(bool, tag = "2")]
    pub parallel_tool_calls: bool,
    /// The ID of the previous response from the model.
    #[prost(string, optional, tag = "3")]
    pub previous_response_id: ::core::option::Option<::prost::alloc::string::String>,
    /// Constrains effort on reasoning for reasoning models. Default to `EFFORT_MEDIUM`.
    #[prost(enumeration = "ReasoningEffort", optional, tag = "4")]
    pub reasoning_effort: ::core::option::Option<i32>,
    /// A number between 0 and 2 used to control the variance of completions.
    /// The smaller the value, the more deterministic the model will become. For
    /// example, if we sample 1000 answers to the same prompt at a temperature of
    /// 0.001, then most of the 1000 answers will be identical. Conversely, if we
    /// conduct the same experiment at a temperature of 2, virtually no two answers
    /// will be identical. Note that increasing the temperature will cause
    /// the model to hallucinate more strongly.
    #[prost(float, optional, tag = "5")]
    pub temperature: ::core::option::Option<f32>,
    /// Formatting constraint on the response.
    #[prost(message, optional, tag = "6")]
    pub response_format: ::core::option::Option<ResponseFormat>,
    /// Controls if the model can, should, or must not use tools.
    #[prost(message, optional, tag = "7")]
    pub tool_choice: ::core::option::Option<ToolChoice>,
    /// A list of tools the model may call. Currently, only functions are supported
    /// as a tool. Use this to provide a list of functions the model may generate
    /// JSON inputs for.
    #[prost(message, repeated, tag = "8")]
    pub tools: ::prost::alloc::vec::Vec<Tool>,
    /// A number between 0 and 1 controlling the likelihood of the model to use
    /// less-common answers. Recall that the model produces a probability for
    /// each token. This means, for any choice of token there are thousands of
    /// possibilities to choose from. This parameter controls the "nucleus sampling
    /// algorithm". Instead of considering every possible token at every step, we
    /// only look at the K tokens who's probabilities exceed `top_p`.
    /// For example, if we set `top_p = 0.9`, then the set of tokens we actually
    /// sample from, will have a probability mass of at least 90%. In practice,
    /// low values will make the model more deterministic.
    #[prost(float, optional, tag = "9")]
    pub top_p: ::core::option::Option<f32>,
    /// An opaque string supplied by the API client (customer) to identify a user.
    /// The string will be stored in the logs and can be used in customer service
    /// requests to identify certain requests.
    #[prost(string, tag = "10")]
    pub user: ::prost::alloc::string::String,
    /// Set the parameters to be used for realtime data. If not set, no realtime data will be acquired by the model.
    #[prost(message, optional, tag = "11")]
    pub search_parameters: ::core::option::Option<SearchParameters>,
    /// Whether to store request and responses. Default is false.
    #[prost(bool, tag = "12")]
    pub store_messages: bool,
    /// Whether to use encrypted thinking for thinking trace rehydration.
    #[prost(bool, tag = "13")]
    pub use_encrypted_content: bool,
    /// Allow the users to control what optional fields to be returned in the response.
    #[prost(enumeration = "IncludeOption", repeated, tag = "14")]
    pub include: ::prost::alloc::vec::Vec<i32>,
}
/// Request to retrieve a stored completion response.
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct GetStoredCompletionRequest {
    /// The response id to be retrieved.
    #[prost(string, tag = "1")]
    pub response_id: ::prost::alloc::string::String,
}
/// Request to delete a stored completion response.
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct DeleteStoredCompletionRequest {
    /// The response id to be deleted.
    #[prost(string, tag = "1")]
    pub response_id: ::prost::alloc::string::String,
}
/// Response for deleting a stored completion.
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct DeleteStoredCompletionResponse {
    /// The response id that was deleted.
    #[prost(string, tag = "1")]
    pub response_id: ::prost::alloc::string::String,
}
/// Holds debug information. Only available to trusted testers.
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct DebugOutput {
    /// Number of attempts made to the model.
    #[prost(int32, tag = "1")]
    pub attempts: i32,
    /// The request received from the user.
    #[prost(string, tag = "2")]
    pub request: ::prost::alloc::string::String,
    /// The prompt sent to the model in text form.
    #[prost(string, tag = "3")]
    pub prompt: ::prost::alloc::string::String,
    /// The JSON-serialized request sent to the inference engine.
    #[prost(string, tag = "9")]
    pub engine_request: ::prost::alloc::string::String,
    /// The response(s) received from the model.
    #[prost(string, repeated, tag = "4")]
    pub responses: ::prost::alloc::vec::Vec<::prost::alloc::string::String>,
    /// The raw chunks returned from the pipeline of samplers.
    #[prost(string, repeated, tag = "12")]
    pub chunks: ::prost::alloc::vec::Vec<::prost::alloc::string::String>,
    /// Number of cache reads
    #[prost(uint32, tag = "5")]
    pub cache_read_count: u32,
    /// Size of cache read
    #[prost(uint64, tag = "6")]
    pub cache_read_input_bytes: u64,
    /// Number of cache writes
    #[prost(uint32, tag = "7")]
    pub cache_write_count: u32,
    /// Size of cache write
    #[prost(uint64, tag = "8")]
    pub cache_write_input_bytes: u64,
    /// The lb address header
    #[prost(string, tag = "10")]
    pub lb_address: ::prost::alloc::string::String,
    /// The tag of the sampler that served this request.
    #[prost(string, tag = "11")]
    pub sampler_tag: ::prost::alloc::string::String,
}
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration)]
#[repr(i32)]
pub enum IncludeOption {
    /// Default value / invalid option.
    Invalid = 0,
    /// Include the encrypted output from the web search tool in the response.
    WebSearchCallOutput = 1,
    /// Include the encrypted output from the X search tool in the response.
    XSearchCallOutput = 2,
    /// Include the plaintext output from the code execution tool in the response.
    CodeExecutionCallOutput = 3,
    /// Include the plaintext output from the collections search tool in the response.
    CollectionsSearchCallOutput = 4,
    /// Include the plaintext output from the attachment search tool in the response.
    AttachmentSearchCallOutput = 5,
    /// Include the plaintext output from the MCP tool in the response.
    McpCallOutput = 6,
    /// Include the inline citations in the final response.
    InlineCitations = 7,
    /// Stream back any chunks that are generated by the model or the agent tools
    /// even if there is no user-visible content in the chunk, e.g. only the usage
    /// statistics are being updated.
    /// The chunks without user-visible content are not streamed to the client when
    /// this option is not included by default.
    /// This option is only available for streaming responses.
    VerboseStreaming = 8,
}
impl IncludeOption {
    /// String value of the enum field names used in the ProtoBuf definition.
    ///
    /// The values are not transformed in any way and thus are considered stable
    /// (if the ProtoBuf definition does not change) and safe for programmatic use.
    pub fn as_str_name(&self) -> &'static str {
        match self {
            Self::Invalid => "INCLUDE_OPTION_INVALID",
            Self::WebSearchCallOutput => "INCLUDE_OPTION_WEB_SEARCH_CALL_OUTPUT",
            Self::XSearchCallOutput => "INCLUDE_OPTION_X_SEARCH_CALL_OUTPUT",
            Self::CodeExecutionCallOutput => "INCLUDE_OPTION_CODE_EXECUTION_CALL_OUTPUT",
            Self::CollectionsSearchCallOutput => {
                "INCLUDE_OPTION_COLLECTIONS_SEARCH_CALL_OUTPUT"
            }
            Self::AttachmentSearchCallOutput => {
                "INCLUDE_OPTION_ATTACHMENT_SEARCH_CALL_OUTPUT"
            }
            Self::McpCallOutput => "INCLUDE_OPTION_MCP_CALL_OUTPUT",
            Self::InlineCitations => "INCLUDE_OPTION_INLINE_CITATIONS",
            Self::VerboseStreaming => "INCLUDE_OPTION_VERBOSE_STREAMING",
        }
    }
    /// Creates an enum from field names used in the ProtoBuf definition.
    pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
        match value {
            "INCLUDE_OPTION_INVALID" => Some(Self::Invalid),
            "INCLUDE_OPTION_WEB_SEARCH_CALL_OUTPUT" => Some(Self::WebSearchCallOutput),
            "INCLUDE_OPTION_X_SEARCH_CALL_OUTPUT" => Some(Self::XSearchCallOutput),
            "INCLUDE_OPTION_CODE_EXECUTION_CALL_OUTPUT" => {
                Some(Self::CodeExecutionCallOutput)
            }
            "INCLUDE_OPTION_COLLECTIONS_SEARCH_CALL_OUTPUT" => {
                Some(Self::CollectionsSearchCallOutput)
            }
            "INCLUDE_OPTION_ATTACHMENT_SEARCH_CALL_OUTPUT" => {
                Some(Self::AttachmentSearchCallOutput)
            }
            "INCLUDE_OPTION_MCP_CALL_OUTPUT" => Some(Self::McpCallOutput),
            "INCLUDE_OPTION_INLINE_CITATIONS" => Some(Self::InlineCitations),
            "INCLUDE_OPTION_VERBOSE_STREAMING" => Some(Self::VerboseStreaming),
            _ => None,
        }
    }
}
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration)]
#[repr(i32)]
pub enum MessageRole {
    /// Default value / invalid role.
    InvalidRole = 0,
    /// User role.
    RoleUser = 1,
    /// Assistant role, normally the response from the model.
    RoleAssistant = 2,
    /// System role, typically for system instructions.
    RoleSystem = 3,
    /// Indicates a return from a tool call. Deprecated in favor of ROLE_TOOL.
    #[deprecated]
    RoleFunction = 4,
    /// Indicates a return from a tool call.
    RoleTool = 5,
}
impl MessageRole {
    /// String value of the enum field names used in the ProtoBuf definition.
    ///
    /// The values are not transformed in any way and thus are considered stable
    /// (if the ProtoBuf definition does not change) and safe for programmatic use.
    pub fn as_str_name(&self) -> &'static str {
        match self {
            Self::InvalidRole => "INVALID_ROLE",
            Self::RoleUser => "ROLE_USER",
            Self::RoleAssistant => "ROLE_ASSISTANT",
            Self::RoleSystem => "ROLE_SYSTEM",
            #[allow(deprecated)]
            Self::RoleFunction => "ROLE_FUNCTION",
            Self::RoleTool => "ROLE_TOOL",
        }
    }
    /// Creates an enum from field names used in the ProtoBuf definition.
    pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
        match value {
            "INVALID_ROLE" => Some(Self::InvalidRole),
            "ROLE_USER" => Some(Self::RoleUser),
            "ROLE_ASSISTANT" => Some(Self::RoleAssistant),
            "ROLE_SYSTEM" => Some(Self::RoleSystem),
            "ROLE_FUNCTION" => Some(#[allow(deprecated)] Self::RoleFunction),
            "ROLE_TOOL" => Some(Self::RoleTool),
            _ => None,
        }
    }
}
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration)]
#[repr(i32)]
pub enum ReasoningEffort {
    InvalidEffort = 0,
    EffortLow = 1,
    EffortMedium = 2,
    EffortHigh = 3,
}
impl ReasoningEffort {
    /// String value of the enum field names used in the ProtoBuf definition.
    ///
    /// The values are not transformed in any way and thus are considered stable
    /// (if the ProtoBuf definition does not change) and safe for programmatic use.
    pub fn as_str_name(&self) -> &'static str {
        match self {
            Self::InvalidEffort => "INVALID_EFFORT",
            Self::EffortLow => "EFFORT_LOW",
            Self::EffortMedium => "EFFORT_MEDIUM",
            Self::EffortHigh => "EFFORT_HIGH",
        }
    }
    /// Creates an enum from field names used in the ProtoBuf definition.
    pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
        match value {
            "INVALID_EFFORT" => Some(Self::InvalidEffort),
            "EFFORT_LOW" => Some(Self::EffortLow),
            "EFFORT_MEDIUM" => Some(Self::EffortMedium),
            "EFFORT_HIGH" => Some(Self::EffortHigh),
            _ => None,
        }
    }
}
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration)]
#[repr(i32)]
pub enum ToolMode {
    /// Invalid tool mode.
    Invalid = 0,
    /// Let the model decide if a tool shall be used.
    Auto = 1,
    /// Force the model to not use tools.
    None = 2,
    /// Force the model to use tools.
    Required = 3,
}
impl ToolMode {
    /// String value of the enum field names used in the ProtoBuf definition.
    ///
    /// The values are not transformed in any way and thus are considered stable
    /// (if the ProtoBuf definition does not change) and safe for programmatic use.
    pub fn as_str_name(&self) -> &'static str {
        match self {
            Self::Invalid => "TOOL_MODE_INVALID",
            Self::Auto => "TOOL_MODE_AUTO",
            Self::None => "TOOL_MODE_NONE",
            Self::Required => "TOOL_MODE_REQUIRED",
        }
    }
    /// Creates an enum from field names used in the ProtoBuf definition.
    pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
        match value {
            "TOOL_MODE_INVALID" => Some(Self::Invalid),
            "TOOL_MODE_AUTO" => Some(Self::Auto),
            "TOOL_MODE_NONE" => Some(Self::None),
            "TOOL_MODE_REQUIRED" => Some(Self::Required),
            _ => None,
        }
    }
}
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration)]
#[repr(i32)]
pub enum FormatType {
    /// Invalid format type.
    Invalid = 0,
    /// Raw text.
    Text = 1,
    /// Any JSON object.
    JsonObject = 2,
    /// Follow a JSON schema.
    JsonSchema = 3,
}
impl FormatType {
    /// String value of the enum field names used in the ProtoBuf definition.
    ///
    /// The values are not transformed in any way and thus are considered stable
    /// (if the ProtoBuf definition does not change) and safe for programmatic use.
    pub fn as_str_name(&self) -> &'static str {
        match self {
            Self::Invalid => "FORMAT_TYPE_INVALID",
            Self::Text => "FORMAT_TYPE_TEXT",
            Self::JsonObject => "FORMAT_TYPE_JSON_OBJECT",
            Self::JsonSchema => "FORMAT_TYPE_JSON_SCHEMA",
        }
    }
    /// Creates an enum from field names used in the ProtoBuf definition.
    pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
        match value {
            "FORMAT_TYPE_INVALID" => Some(Self::Invalid),
            "FORMAT_TYPE_TEXT" => Some(Self::Text),
            "FORMAT_TYPE_JSON_OBJECT" => Some(Self::JsonObject),
            "FORMAT_TYPE_JSON_SCHEMA" => Some(Self::JsonSchema),
            _ => None,
        }
    }
}
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration)]
#[repr(i32)]
pub enum ToolCallType {
    Invalid = 0,
    /// Indicates the tool is a client-side tool, and should be executed on client side.
    /// Maps to `function_call` type in OAI Responses API.
    ClientSideTool = 1,
    /// Indicates the tool is a server-side web_search tool, and client side won't need to execute.
    /// Maps to `web_search_call` type in OAI Responses API.
    WebSearchTool = 2,
    /// Indicates the tool is a server-side x_search tool, and client side won't need to execute.
    /// Maps to `x_search_call` type in OAI Responses API.
    XSearchTool = 3,
    /// Indicates the tool is a server-side code_execution tool, and client side won't need to execute.
    /// Maps to `code_interpreter_call` type in OAI Responses API.
    CodeExecutionTool = 4,
    /// Indicates the tool is a server-side collections_search tool, and client side won't need to execute.
    /// Maps to `file_search_call` type in OAI Responses API.
    CollectionsSearchTool = 5,
    /// Indicates the tool is a server-side mcp_tool, and client side won't need to execute.
    /// Maps to `mcp_call` type in OAI Responses API.
    McpTool = 6,
    /// Indicates the tool is a server-side attachment_search tool, and client side won't need to execute.
    /// Maps to `attachment_search_call` type in OAI Responses API.
    AttachmentSearchTool = 7,
}
impl ToolCallType {
    /// String value of the enum field names used in the ProtoBuf definition.
    ///
    /// The values are not transformed in any way and thus are considered stable
    /// (if the ProtoBuf definition does not change) and safe for programmatic use.
    pub fn as_str_name(&self) -> &'static str {
        match self {
            Self::Invalid => "TOOL_CALL_TYPE_INVALID",
            Self::ClientSideTool => "TOOL_CALL_TYPE_CLIENT_SIDE_TOOL",
            Self::WebSearchTool => "TOOL_CALL_TYPE_WEB_SEARCH_TOOL",
            Self::XSearchTool => "TOOL_CALL_TYPE_X_SEARCH_TOOL",
            Self::CodeExecutionTool => "TOOL_CALL_TYPE_CODE_EXECUTION_TOOL",
            Self::CollectionsSearchTool => "TOOL_CALL_TYPE_COLLECTIONS_SEARCH_TOOL",
            Self::McpTool => "TOOL_CALL_TYPE_MCP_TOOL",
            Self::AttachmentSearchTool => "TOOL_CALL_TYPE_ATTACHMENT_SEARCH_TOOL",
        }
    }
    /// Creates an enum from field names used in the ProtoBuf definition.
    pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
        match value {
            "TOOL_CALL_TYPE_INVALID" => Some(Self::Invalid),
            "TOOL_CALL_TYPE_CLIENT_SIDE_TOOL" => Some(Self::ClientSideTool),
            "TOOL_CALL_TYPE_WEB_SEARCH_TOOL" => Some(Self::WebSearchTool),
            "TOOL_CALL_TYPE_X_SEARCH_TOOL" => Some(Self::XSearchTool),
            "TOOL_CALL_TYPE_CODE_EXECUTION_TOOL" => Some(Self::CodeExecutionTool),
            "TOOL_CALL_TYPE_COLLECTIONS_SEARCH_TOOL" => Some(Self::CollectionsSearchTool),
            "TOOL_CALL_TYPE_MCP_TOOL" => Some(Self::McpTool),
            "TOOL_CALL_TYPE_ATTACHMENT_SEARCH_TOOL" => Some(Self::AttachmentSearchTool),
            _ => None,
        }
    }
}
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration)]
#[repr(i32)]
pub enum ToolCallStatus {
    /// The tool call is in progress.
    InProgress = 0,
    /// The tool call is completed.
    Completed = 1,
    /// The tool call is incomplete.
    Incomplete = 2,
    /// The tool call is failed.
    Failed = 3,
}
impl ToolCallStatus {
    /// String value of the enum field names used in the ProtoBuf definition.
    ///
    /// The values are not transformed in any way and thus are considered stable
    /// (if the ProtoBuf definition does not change) and safe for programmatic use.
    pub fn as_str_name(&self) -> &'static str {
        match self {
            Self::InProgress => "TOOL_CALL_STATUS_IN_PROGRESS",
            Self::Completed => "TOOL_CALL_STATUS_COMPLETED",
            Self::Incomplete => "TOOL_CALL_STATUS_INCOMPLETE",
            Self::Failed => "TOOL_CALL_STATUS_FAILED",
        }
    }
    /// Creates an enum from field names used in the ProtoBuf definition.
    pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
        match value {
            "TOOL_CALL_STATUS_IN_PROGRESS" => Some(Self::InProgress),
            "TOOL_CALL_STATUS_COMPLETED" => Some(Self::Completed),
            "TOOL_CALL_STATUS_INCOMPLETE" => Some(Self::Incomplete),
            "TOOL_CALL_STATUS_FAILED" => Some(Self::Failed),
            _ => None,
        }
    }
}
/// Mode to control the web search.
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration)]
#[repr(i32)]
pub enum SearchMode {
    InvalidSearchMode = 0,
    OffSearchMode = 1,
    OnSearchMode = 2,
    AutoSearchMode = 3,
}
impl SearchMode {
    /// String value of the enum field names used in the ProtoBuf definition.
    ///
    /// The values are not transformed in any way and thus are considered stable
    /// (if the ProtoBuf definition does not change) and safe for programmatic use.
    pub fn as_str_name(&self) -> &'static str {
        match self {
            Self::InvalidSearchMode => "INVALID_SEARCH_MODE",
            Self::OffSearchMode => "OFF_SEARCH_MODE",
            Self::OnSearchMode => "ON_SEARCH_MODE",
            Self::AutoSearchMode => "AUTO_SEARCH_MODE",
        }
    }
    /// Creates an enum from field names used in the ProtoBuf definition.
    pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
        match value {
            "INVALID_SEARCH_MODE" => Some(Self::InvalidSearchMode),
            "OFF_SEARCH_MODE" => Some(Self::OffSearchMode),
            "ON_SEARCH_MODE" => Some(Self::OnSearchMode),
            "AUTO_SEARCH_MODE" => Some(Self::AutoSearchMode),
            _ => None,
        }
    }
}
/// Generated client implementations.
pub mod chat_client {
    #![allow(
        unused_variables,
        dead_code,
        missing_docs,
        clippy::wildcard_imports,
        clippy::let_unit_value,
    )]
    use tonic::codegen::*;
    use tonic::codegen::http::Uri;
    /// An API that exposes our language models via a Chat interface.
    #[derive(Debug, Clone)]
    pub struct ChatClient<T> {
        inner: tonic::client::Grpc<T>,
    }
    impl ChatClient<tonic::transport::Channel> {
        /// Attempt to create a new client by connecting to a given endpoint.
        pub async fn connect<D>(dst: D) -> Result<Self, tonic::transport::Error>
        where
            D: TryInto<tonic::transport::Endpoint>,
            D::Error: Into<StdError>,
        {
            let conn = tonic::transport::Endpoint::new(dst)?.connect().await?;
            Ok(Self::new(conn))
        }
    }
    impl<T> ChatClient<T>
    where
        T: tonic::client::GrpcService<tonic::body::Body>,
        T::Error: Into<StdError>,
        T::ResponseBody: Body<Data = Bytes> + std::marker::Send + 'static,
        <T::ResponseBody as Body>::Error: Into<StdError> + std::marker::Send,
    {
        pub fn new(inner: T) -> Self {
            let inner = tonic::client::Grpc::new(inner);
            Self { inner }
        }
        pub fn with_origin(inner: T, origin: Uri) -> Self {
            let inner = tonic::client::Grpc::with_origin(inner, origin);
            Self { inner }
        }
        pub fn with_interceptor<F>(
            inner: T,
            interceptor: F,
        ) -> ChatClient<InterceptedService<T, F>>
        where
            F: tonic::service::Interceptor,
            T::ResponseBody: Default,
            T: tonic::codegen::Service<
                http::Request<tonic::body::Body>,
                Response = http::Response<
                    <T as tonic::client::GrpcService<tonic::body::Body>>::ResponseBody,
                >,
            >,
            <T as tonic::codegen::Service<
                http::Request<tonic::body::Body>,
            >>::Error: Into<StdError> + std::marker::Send + std::marker::Sync,
        {
            ChatClient::new(InterceptedService::new(inner, interceptor))
        }
        /// Compress requests with the given encoding.
        ///
        /// This requires the server to support it otherwise it might respond with an
        /// error.
        #[must_use]
        pub fn send_compressed(mut self, encoding: CompressionEncoding) -> Self {
            self.inner = self.inner.send_compressed(encoding);
            self
        }
        /// Enable decompressing responses.
        #[must_use]
        pub fn accept_compressed(mut self, encoding: CompressionEncoding) -> Self {
            self.inner = self.inner.accept_compressed(encoding);
            self
        }
        /// Limits the maximum size of a decoded message.
        ///
        /// Default: `4MB`
        #[must_use]
        pub fn max_decoding_message_size(mut self, limit: usize) -> Self {
            self.inner = self.inner.max_decoding_message_size(limit);
            self
        }
        /// Limits the maximum size of an encoded message.
        ///
        /// Default: `usize::MAX`
        #[must_use]
        pub fn max_encoding_message_size(mut self, limit: usize) -> Self {
            self.inner = self.inner.max_encoding_message_size(limit);
            self
        }
        /// Samples a response from the model and blocks until the response has been
        /// fully generated.
        pub async fn get_completion(
            &mut self,
            request: impl tonic::IntoRequest<super::GetCompletionsRequest>,
        ) -> std::result::Result<
            tonic::Response<super::GetChatCompletionResponse>,
            tonic::Status,
        > {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::unknown(
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic_prost::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/xai_api.Chat/GetCompletion",
            );
            let mut req = request.into_request();
            req.extensions_mut()
                .insert(GrpcMethod::new("xai_api.Chat", "GetCompletion"));
            self.inner.unary(req, path, codec).await
        }
        /// Samples a response from the model and streams out the model tokens as they
        /// are being generated.
        pub async fn get_completion_chunk(
            &mut self,
            request: impl tonic::IntoRequest<super::GetCompletionsRequest>,
        ) -> std::result::Result<
            tonic::Response<tonic::codec::Streaming<super::GetChatCompletionChunk>>,
            tonic::Status,
        > {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::unknown(
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic_prost::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/xai_api.Chat/GetCompletionChunk",
            );
            let mut req = request.into_request();
            req.extensions_mut()
                .insert(GrpcMethod::new("xai_api.Chat", "GetCompletionChunk"));
            self.inner.server_streaming(req, path, codec).await
        }
        /// Starts sampling of the model and immediately returns a response containing
        /// a request id. The request id may be used to poll
        /// the `GetDeferredCompletion` RPC.
        pub async fn start_deferred_completion(
            &mut self,
            request: impl tonic::IntoRequest<super::GetCompletionsRequest>,
        ) -> std::result::Result<
            tonic::Response<super::StartDeferredResponse>,
            tonic::Status,
        > {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::unknown(
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic_prost::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/xai_api.Chat/StartDeferredCompletion",
            );
            let mut req = request.into_request();
            req.extensions_mut()
                .insert(GrpcMethod::new("xai_api.Chat", "StartDeferredCompletion"));
            self.inner.unary(req, path, codec).await
        }
        /// Gets the result of a deferred completion started by calling `StartDeferredCompletion`.
        pub async fn get_deferred_completion(
            &mut self,
            request: impl tonic::IntoRequest<super::GetDeferredRequest>,
        ) -> std::result::Result<
            tonic::Response<super::GetDeferredCompletionResponse>,
            tonic::Status,
        > {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::unknown(
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic_prost::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/xai_api.Chat/GetDeferredCompletion",
            );
            let mut req = request.into_request();
            req.extensions_mut()
                .insert(GrpcMethod::new("xai_api.Chat", "GetDeferredCompletion"));
            self.inner.unary(req, path, codec).await
        }
        /// Retrieve a stored response using the response ID.
        pub async fn get_stored_completion(
            &mut self,
            request: impl tonic::IntoRequest<super::GetStoredCompletionRequest>,
        ) -> std::result::Result<
            tonic::Response<super::GetChatCompletionResponse>,
            tonic::Status,
        > {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::unknown(
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic_prost::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/xai_api.Chat/GetStoredCompletion",
            );
            let mut req = request.into_request();
            req.extensions_mut()
                .insert(GrpcMethod::new("xai_api.Chat", "GetStoredCompletion"));
            self.inner.unary(req, path, codec).await
        }
        /// Delete a stored response using the response ID.
        pub async fn delete_stored_completion(
            &mut self,
            request: impl tonic::IntoRequest<super::DeleteStoredCompletionRequest>,
        ) -> std::result::Result<
            tonic::Response<super::DeleteStoredCompletionResponse>,
            tonic::Status,
        > {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::unknown(
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic_prost::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/xai_api.Chat/DeleteStoredCompletion",
            );
            let mut req = request.into_request();
            req.extensions_mut()
                .insert(GrpcMethod::new("xai_api.Chat", "DeleteStoredCompletion"));
            self.inner.unary(req, path, codec).await
        }
    }
}
/// Request message for generating embeddings.
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct EmbedRequest {
    /// The entities to embed. Note that not every model supports images and text.
    /// Some models are text-only and some are image-only. You can at most embed
    /// 128 inputs in a single request.
    #[prost(message, repeated, tag = "1")]
    pub input: ::prost::alloc::vec::Vec<EmbedInput>,
    /// Name or alias of the embedding model to use.
    #[prost(string, tag = "2")]
    pub model: ::prost::alloc::string::String,
    /// Format of the returned embeddings.
    #[prost(enumeration = "EmbedEncodingFormat", tag = "3")]
    pub encoding_format: i32,
    /// An opaque string supplied by the API client (customer) to identify a user.
    /// The string will be stored in the logs and can be used in customer service
    /// requests to identify certain requests.
    #[prost(string, tag = "4")]
    pub user: ::prost::alloc::string::String,
}
/// Input content to be embedded.
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct EmbedInput {
    #[prost(oneof = "embed_input::Input", tags = "1, 2")]
    pub input: ::core::option::Option<embed_input::Input>,
}
/// Nested message and enum types in `EmbedInput`.
pub mod embed_input {
    #[derive(serde::Serialize, serde::Deserialize)]
    #[derive(Clone, PartialEq, Eq, Hash, ::prost::Oneof)]
    pub enum Input {
        /// A string to be embedded.
        #[prost(string, tag = "1")]
        String(::prost::alloc::string::String),
        /// An image to be embedded.
        #[prost(message, tag = "2")]
        ImageUrl(super::ImageUrlContent),
    }
}
/// Response object for the `Embed` RPC.
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct EmbedResponse {
    /// An identifier of this request. The same ID will be used in your billing
    /// records.
    #[prost(string, tag = "1")]
    pub id: ::prost::alloc::string::String,
    /// The embeddings generated from the inputs.
    #[prost(message, repeated, tag = "2")]
    pub embeddings: ::prost::alloc::vec::Vec<Embedding>,
    /// The usage associated with this request.
    #[prost(message, optional, tag = "3")]
    pub usage: ::core::option::Option<EmbeddingUsage>,
    /// The name of the model used for the request. This model name contains
    /// the actual model name used rather than any aliases.
    /// This means it can be `embed-0205` even when the request was specifying
    /// `embed-latest`.
    #[prost(string, tag = "4")]
    pub model: ::prost::alloc::string::String,
    /// This fingerprint represents the backend configuration that the model runs
    /// with.
    #[prost(string, tag = "5")]
    pub system_fingerprint: ::prost::alloc::string::String,
}
/// Holds the embedding vector for a single embedding input.
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct Embedding {
    /// The index of the input this embedding was produced from.
    #[prost(int32, tag = "1")]
    pub index: i32,
    /// The feature vectors derived from the inputs. Note that some inputs such as
    /// images may produce multiple feature vectors.
    #[prost(message, repeated, tag = "2")]
    pub embeddings: ::prost::alloc::vec::Vec<FeatureVector>,
}
/// A single feature vector.
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct FeatureVector {
    /// The feature vector encoded as an array of floats. Only populated if
    /// the encoding format is FORMAT_FLOAT.
    #[prost(float, repeated, tag = "1")]
    pub float_array: ::prost::alloc::vec::Vec<f32>,
    /// The feature vector encoded as a base64 string. Only populated if
    /// the encoding format is FORMAT_BASE64.
    #[prost(string, tag = "2")]
    pub base64_array: ::prost::alloc::string::String,
}
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration)]
#[repr(i32)]
pub enum EmbedEncodingFormat {
    /// Invalid format.
    FormatInvalid = 0,
    /// Returns the embeddings as an array of floats.
    FormatFloat = 1,
    /// Returns the embeddings as a base64-encoded string.
    FormatBase64 = 2,
}
impl EmbedEncodingFormat {
    /// String value of the enum field names used in the ProtoBuf definition.
    ///
    /// The values are not transformed in any way and thus are considered stable
    /// (if the ProtoBuf definition does not change) and safe for programmatic use.
    pub fn as_str_name(&self) -> &'static str {
        match self {
            Self::FormatInvalid => "FORMAT_INVALID",
            Self::FormatFloat => "FORMAT_FLOAT",
            Self::FormatBase64 => "FORMAT_BASE64",
        }
    }
    /// Creates an enum from field names used in the ProtoBuf definition.
    pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
        match value {
            "FORMAT_INVALID" => Some(Self::FormatInvalid),
            "FORMAT_FLOAT" => Some(Self::FormatFloat),
            "FORMAT_BASE64" => Some(Self::FormatBase64),
            _ => None,
        }
    }
}
/// Generated client implementations.
pub mod embedder_client {
    #![allow(
        unused_variables,
        dead_code,
        missing_docs,
        clippy::wildcard_imports,
        clippy::let_unit_value,
    )]
    use tonic::codegen::*;
    use tonic::codegen::http::Uri;
    /// An API service for interaction with available embedding models.
    #[derive(Debug, Clone)]
    pub struct EmbedderClient<T> {
        inner: tonic::client::Grpc<T>,
    }
    impl EmbedderClient<tonic::transport::Channel> {
        /// Attempt to create a new client by connecting to a given endpoint.
        pub async fn connect<D>(dst: D) -> Result<Self, tonic::transport::Error>
        where
            D: TryInto<tonic::transport::Endpoint>,
            D::Error: Into<StdError>,
        {
            let conn = tonic::transport::Endpoint::new(dst)?.connect().await?;
            Ok(Self::new(conn))
        }
    }
    impl<T> EmbedderClient<T>
    where
        T: tonic::client::GrpcService<tonic::body::Body>,
        T::Error: Into<StdError>,
        T::ResponseBody: Body<Data = Bytes> + std::marker::Send + 'static,
        <T::ResponseBody as Body>::Error: Into<StdError> + std::marker::Send,
    {
        pub fn new(inner: T) -> Self {
            let inner = tonic::client::Grpc::new(inner);
            Self { inner }
        }
        pub fn with_origin(inner: T, origin: Uri) -> Self {
            let inner = tonic::client::Grpc::with_origin(inner, origin);
            Self { inner }
        }
        pub fn with_interceptor<F>(
            inner: T,
            interceptor: F,
        ) -> EmbedderClient<InterceptedService<T, F>>
        where
            F: tonic::service::Interceptor,
            T::ResponseBody: Default,
            T: tonic::codegen::Service<
                http::Request<tonic::body::Body>,
                Response = http::Response<
                    <T as tonic::client::GrpcService<tonic::body::Body>>::ResponseBody,
                >,
            >,
            <T as tonic::codegen::Service<
                http::Request<tonic::body::Body>,
            >>::Error: Into<StdError> + std::marker::Send + std::marker::Sync,
        {
            EmbedderClient::new(InterceptedService::new(inner, interceptor))
        }
        /// Compress requests with the given encoding.
        ///
        /// This requires the server to support it otherwise it might respond with an
        /// error.
        #[must_use]
        pub fn send_compressed(mut self, encoding: CompressionEncoding) -> Self {
            self.inner = self.inner.send_compressed(encoding);
            self
        }
        /// Enable decompressing responses.
        #[must_use]
        pub fn accept_compressed(mut self, encoding: CompressionEncoding) -> Self {
            self.inner = self.inner.accept_compressed(encoding);
            self
        }
        /// Limits the maximum size of a decoded message.
        ///
        /// Default: `4MB`
        #[must_use]
        pub fn max_decoding_message_size(mut self, limit: usize) -> Self {
            self.inner = self.inner.max_decoding_message_size(limit);
            self
        }
        /// Limits the maximum size of an encoded message.
        ///
        /// Default: `usize::MAX`
        #[must_use]
        pub fn max_encoding_message_size(mut self, limit: usize) -> Self {
            self.inner = self.inner.max_encoding_message_size(limit);
            self
        }
        /// Produces one embedding for each input object. The size of the produced
        /// feature vectors depends on the chosen model.
        pub async fn embed(
            &mut self,
            request: impl tonic::IntoRequest<super::EmbedRequest>,
        ) -> std::result::Result<tonic::Response<super::EmbedResponse>, tonic::Status> {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::unknown(
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic_prost::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static("/xai_api.Embedder/Embed");
            let mut req = request.into_request();
            req.extensions_mut().insert(GrpcMethod::new("xai_api.Embedder", "Embed"));
            self.inner.unary(req, path, codec).await
        }
    }
}
/// Request to get details of a specific model by name.
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct GetModelRequest {
    /// The name of the model to retrieve details about.
    #[prost(string, tag = "1")]
    pub name: ::prost::alloc::string::String,
}
/// Describes a language model available on the platform.
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct LanguageModel {
    /// The model name used in API requests/responses.
    #[prost(string, tag = "1")]
    pub name: ::prost::alloc::string::String,
    /// The aliases of the name, which can also be used in lieu of name in the API
    /// requests.
    #[prost(string, repeated, tag = "11")]
    pub aliases: ::prost::alloc::vec::Vec<::prost::alloc::string::String>,
    /// The version number of this model. Used to identify minor updates when
    /// the model name is not changed.
    #[prost(string, tag = "2")]
    pub version: ::prost::alloc::string::String,
    /// The supported input modalities of the model.
    #[prost(enumeration = "Modality", repeated, tag = "3")]
    pub input_modalities: ::prost::alloc::vec::Vec<i32>,
    /// The supported output modalities of the model.
    #[prost(enumeration = "Modality", repeated, tag = "4")]
    pub output_modalities: ::prost::alloc::vec::Vec<i32>,
    /// The price (in 1/100 USD cents) per one million text prompt tokens.
    #[prost(int64, tag = "5")]
    pub prompt_text_token_price: i64,
    /// The price (in 1/100 USD cents) per one million image prompt tokens.
    #[prost(int64, tag = "6")]
    pub prompt_image_token_price: i64,
    /// The price (in USD cents) per 100 million cached text prompt tokens.
    #[prost(int64, tag = "12")]
    pub cached_prompt_token_price: i64,
    /// The price (in 1/100 USD cents) per one million text completion token.
    #[prost(int64, tag = "7")]
    pub completion_text_token_price: i64,
    /// The price (in 1/100 USD cents) per one million searches.
    #[prost(int64, tag = "13")]
    pub search_price: i64,
    /// The creation time of the model.
    #[prost(message, optional, tag = "8")]
    pub created: ::core::option::Option<::prost_wkt_types::Timestamp>,
    /// Maximum length of the prompt/input (this includes tokens of all kinds).
    /// This is typically known as the context length of the model.
    #[prost(int32, tag = "9")]
    pub max_prompt_length: i32,
    /// Fingerprint of the unique configuration of the model.
    #[prost(string, tag = "10")]
    pub system_fingerprint: ::prost::alloc::string::String,
}
/// Response from ListLanguageModels including a list of language models.
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ListLanguageModelsResponse {
    /// A list of language models.
    #[prost(message, repeated, tag = "1")]
    pub models: ::prost::alloc::vec::Vec<LanguageModel>,
}
/// Describes an embedding model available on the platform.
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct EmbeddingModel {
    /// The name under which the model is available in the API.
    #[prost(string, tag = "1")]
    pub name: ::prost::alloc::string::String,
    /// The aliases of the name, which can also be used in lieu of name in the API
    /// requests.
    #[prost(string, repeated, tag = "11")]
    pub aliases: ::prost::alloc::vec::Vec<::prost::alloc::string::String>,
    /// The version number of this model. Used to identify minor updates when
    /// the model name is not changed.
    #[prost(string, tag = "2")]
    pub version: ::prost::alloc::string::String,
    /// The supported input modalities of the model.
    #[prost(enumeration = "Modality", repeated, tag = "3")]
    pub input_modalities: ::prost::alloc::vec::Vec<i32>,
    /// The supported output modalities of the model.
    #[prost(enumeration = "Modality", repeated, tag = "4")]
    pub output_modalities: ::prost::alloc::vec::Vec<i32>,
    /// The price (in 1/100 USD cents) per one million text prompt tokens.
    #[prost(int64, tag = "5")]
    pub prompt_text_token_price: i64,
    /// The price (in 1/100 USD cents) per one million image prompt tokens.
    #[prost(int64, tag = "6")]
    pub prompt_image_token_price: i64,
    /// The creation time of the model.
    #[prost(message, optional, tag = "7")]
    pub created: ::core::option::Option<::prost_wkt_types::Timestamp>,
    /// Fingerprint of the unique configuration of the model.
    #[prost(string, tag = "8")]
    pub system_fingerprint: ::prost::alloc::string::String,
}
/// Response from ListEmbeddingModels including a list of embedding models.
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ListEmbeddingModelsResponse {
    /// A list of embedding model(s).
    #[prost(message, repeated, tag = "1")]
    pub models: ::prost::alloc::vec::Vec<EmbeddingModel>,
}
/// Describes a language model available on the platform.
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct ImageGenerationModel {
    /// The model name used in API requests/responses.
    #[prost(string, tag = "1")]
    pub name: ::prost::alloc::string::String,
    /// The aliases of the name, which can also be used in lieu of name in the API
    /// requests.
    #[prost(string, repeated, tag = "11")]
    pub aliases: ::prost::alloc::vec::Vec<::prost::alloc::string::String>,
    /// The version number of this model. Used to identify minor updates when
    /// the model name is not changed.
    #[prost(string, tag = "2")]
    pub version: ::prost::alloc::string::String,
    /// The supported input modalities of the model.
    #[prost(enumeration = "Modality", repeated, tag = "3")]
    pub input_modalities: ::prost::alloc::vec::Vec<i32>,
    /// The supported output modalities of the model.
    #[prost(enumeration = "Modality", repeated, tag = "6")]
    pub output_modalities: ::prost::alloc::vec::Vec<i32>,
    /// The price (in USD cents) per image.
    #[prost(int64, tag = "12")]
    pub image_price: i64,
    /// When the language model was created.
    #[prost(message, optional, tag = "8")]
    pub created: ::core::option::Option<::prost_wkt_types::Timestamp>,
    /// Maximum length of the prompt/input (this includes tokens of all kinds).
    /// This is typically known as the context length of the model.
    #[prost(int32, tag = "9")]
    pub max_prompt_length: i32,
    /// Fingerprint of the unique configuration of the model.
    #[prost(string, tag = "10")]
    pub system_fingerprint: ::prost::alloc::string::String,
}
/// Response from ListImageGenerationModels including a list of image generation
/// models.
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ListImageGenerationModelsResponse {
    /// A list of image generation models.
    #[prost(message, repeated, tag = "1")]
    pub models: ::prost::alloc::vec::Vec<ImageGenerationModel>,
}
/// Modalities supported by a model input/output.
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration)]
#[repr(i32)]
pub enum Modality {
    /// Invalid modality.
    InvalidModality = 0,
    /// Text input/output.
    Text = 1,
    /// Image input/output.
    Image = 2,
    /// Embedding input/output.
    Embedding = 3,
}
impl Modality {
    /// String value of the enum field names used in the ProtoBuf definition.
    ///
    /// The values are not transformed in any way and thus are considered stable
    /// (if the ProtoBuf definition does not change) and safe for programmatic use.
    pub fn as_str_name(&self) -> &'static str {
        match self {
            Self::InvalidModality => "INVALID_MODALITY",
            Self::Text => "TEXT",
            Self::Image => "IMAGE",
            Self::Embedding => "EMBEDDING",
        }
    }
    /// Creates an enum from field names used in the ProtoBuf definition.
    pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
        match value {
            "INVALID_MODALITY" => Some(Self::InvalidModality),
            "TEXT" => Some(Self::Text),
            "IMAGE" => Some(Self::Image),
            "EMBEDDING" => Some(Self::Embedding),
            _ => None,
        }
    }
}
/// Generated client implementations.
pub mod models_client {
    #![allow(
        unused_variables,
        dead_code,
        missing_docs,
        clippy::wildcard_imports,
        clippy::let_unit_value,
    )]
    use tonic::codegen::*;
    use tonic::codegen::http::Uri;
    /// An API service that let users get details of available models on the
    /// platform.
    #[derive(Debug, Clone)]
    pub struct ModelsClient<T> {
        inner: tonic::client::Grpc<T>,
    }
    impl ModelsClient<tonic::transport::Channel> {
        /// Attempt to create a new client by connecting to a given endpoint.
        pub async fn connect<D>(dst: D) -> Result<Self, tonic::transport::Error>
        where
            D: TryInto<tonic::transport::Endpoint>,
            D::Error: Into<StdError>,
        {
            let conn = tonic::transport::Endpoint::new(dst)?.connect().await?;
            Ok(Self::new(conn))
        }
    }
    impl<T> ModelsClient<T>
    where
        T: tonic::client::GrpcService<tonic::body::Body>,
        T::Error: Into<StdError>,
        T::ResponseBody: Body<Data = Bytes> + std::marker::Send + 'static,
        <T::ResponseBody as Body>::Error: Into<StdError> + std::marker::Send,
    {
        pub fn new(inner: T) -> Self {
            let inner = tonic::client::Grpc::new(inner);
            Self { inner }
        }
        pub fn with_origin(inner: T, origin: Uri) -> Self {
            let inner = tonic::client::Grpc::with_origin(inner, origin);
            Self { inner }
        }
        pub fn with_interceptor<F>(
            inner: T,
            interceptor: F,
        ) -> ModelsClient<InterceptedService<T, F>>
        where
            F: tonic::service::Interceptor,
            T::ResponseBody: Default,
            T: tonic::codegen::Service<
                http::Request<tonic::body::Body>,
                Response = http::Response<
                    <T as tonic::client::GrpcService<tonic::body::Body>>::ResponseBody,
                >,
            >,
            <T as tonic::codegen::Service<
                http::Request<tonic::body::Body>,
            >>::Error: Into<StdError> + std::marker::Send + std::marker::Sync,
        {
            ModelsClient::new(InterceptedService::new(inner, interceptor))
        }
        /// Compress requests with the given encoding.
        ///
        /// This requires the server to support it otherwise it might respond with an
        /// error.
        #[must_use]
        pub fn send_compressed(mut self, encoding: CompressionEncoding) -> Self {
            self.inner = self.inner.send_compressed(encoding);
            self
        }
        /// Enable decompressing responses.
        #[must_use]
        pub fn accept_compressed(mut self, encoding: CompressionEncoding) -> Self {
            self.inner = self.inner.accept_compressed(encoding);
            self
        }
        /// Limits the maximum size of a decoded message.
        ///
        /// Default: `4MB`
        #[must_use]
        pub fn max_decoding_message_size(mut self, limit: usize) -> Self {
            self.inner = self.inner.max_decoding_message_size(limit);
            self
        }
        /// Limits the maximum size of an encoded message.
        ///
        /// Default: `usize::MAX`
        #[must_use]
        pub fn max_encoding_message_size(mut self, limit: usize) -> Self {
            self.inner = self.inner.max_encoding_message_size(limit);
            self
        }
        /// Lists all language models available to your team (based on the API key).
        pub async fn list_language_models(
            &mut self,
            request: impl tonic::IntoRequest<()>,
        ) -> std::result::Result<
            tonic::Response<super::ListLanguageModelsResponse>,
            tonic::Status,
        > {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::unknown(
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic_prost::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/xai_api.Models/ListLanguageModels",
            );
            let mut req = request.into_request();
            req.extensions_mut()
                .insert(GrpcMethod::new("xai_api.Models", "ListLanguageModels"));
            self.inner.unary(req, path, codec).await
        }
        /// Lists all embedding models available to your team (based on the API key).
        pub async fn list_embedding_models(
            &mut self,
            request: impl tonic::IntoRequest<()>,
        ) -> std::result::Result<
            tonic::Response<super::ListEmbeddingModelsResponse>,
            tonic::Status,
        > {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::unknown(
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic_prost::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/xai_api.Models/ListEmbeddingModels",
            );
            let mut req = request.into_request();
            req.extensions_mut()
                .insert(GrpcMethod::new("xai_api.Models", "ListEmbeddingModels"));
            self.inner.unary(req, path, codec).await
        }
        /// Lists all image generation models available to your team (based on the API key).
        pub async fn list_image_generation_models(
            &mut self,
            request: impl tonic::IntoRequest<()>,
        ) -> std::result::Result<
            tonic::Response<super::ListImageGenerationModelsResponse>,
            tonic::Status,
        > {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::unknown(
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic_prost::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/xai_api.Models/ListImageGenerationModels",
            );
            let mut req = request.into_request();
            req.extensions_mut()
                .insert(GrpcMethod::new("xai_api.Models", "ListImageGenerationModels"));
            self.inner.unary(req, path, codec).await
        }
        /// Get details of a specific language model by model name.
        pub async fn get_language_model(
            &mut self,
            request: impl tonic::IntoRequest<super::GetModelRequest>,
        ) -> std::result::Result<tonic::Response<super::LanguageModel>, tonic::Status> {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::unknown(
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic_prost::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/xai_api.Models/GetLanguageModel",
            );
            let mut req = request.into_request();
            req.extensions_mut()
                .insert(GrpcMethod::new("xai_api.Models", "GetLanguageModel"));
            self.inner.unary(req, path, codec).await
        }
        /// Get details of a specific embedding model by model name.
        pub async fn get_embedding_model(
            &mut self,
            request: impl tonic::IntoRequest<super::GetModelRequest>,
        ) -> std::result::Result<tonic::Response<super::EmbeddingModel>, tonic::Status> {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::unknown(
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic_prost::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/xai_api.Models/GetEmbeddingModel",
            );
            let mut req = request.into_request();
            req.extensions_mut()
                .insert(GrpcMethod::new("xai_api.Models", "GetEmbeddingModel"));
            self.inner.unary(req, path, codec).await
        }
        /// Get details of a specific image generation model by model name.
        pub async fn get_image_generation_model(
            &mut self,
            request: impl tonic::IntoRequest<super::GetModelRequest>,
        ) -> std::result::Result<
            tonic::Response<super::ImageGenerationModel>,
            tonic::Status,
        > {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::unknown(
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic_prost::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/xai_api.Models/GetImageGenerationModel",
            );
            let mut req = request.into_request();
            req.extensions_mut()
                .insert(GrpcMethod::new("xai_api.Models", "GetImageGenerationModel"));
            self.inner.unary(req, path, codec).await
        }
    }
}
/// Request to convert text to a sequence of tokens.
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct TokenizeTextRequest {
    /// Text to tokenize.
    #[prost(string, tag = "1")]
    pub text: ::prost::alloc::string::String,
    /// Name or alias of the model used for tokenization.
    #[prost(string, tag = "2")]
    pub model: ::prost::alloc::string::String,
    /// An opaque string supplied by the API client (customer) to identify a user.
    /// The string will be stored in the logs and can be used in customer service
    /// requests to identify certain requests.
    #[prost(string, tag = "3")]
    pub user: ::prost::alloc::string::String,
}
/// Information on a token.
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, PartialEq, Eq, Hash, ::prost::Message)]
pub struct Token {
    /// ID of the token.
    #[prost(uint32, tag = "1")]
    pub token_id: u32,
    /// String snippet of the token.
    #[prost(string, tag = "2")]
    pub string_token: ::prost::alloc::string::String,
    /// Bytes representing the token.
    #[prost(bytes = "vec", tag = "4")]
    pub token_bytes: ::prost::alloc::vec::Vec<u8>,
}
/// Response including the tokenization result.
#[derive(serde::Serialize, serde::Deserialize)]
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct TokenizeTextResponse {
    /// The sequence of tokens. This is the output of the tokenization process.
    #[prost(message, repeated, tag = "1")]
    pub tokens: ::prost::alloc::vec::Vec<Token>,
    /// The name of the model used for the request. This model name contains
    /// the actual model name used rather than any aliases.
    /// This means the this can be `grok-2-1212` even when the request was
    /// specifying `grok-2-latest`.
    #[prost(string, tag = "2")]
    pub model: ::prost::alloc::string::String,
}
/// Generated client implementations.
pub mod tokenize_client {
    #![allow(
        unused_variables,
        dead_code,
        missing_docs,
        clippy::wildcard_imports,
        clippy::let_unit_value,
    )]
    use tonic::codegen::*;
    use tonic::codegen::http::Uri;
    /// An API service to tokenize input prompts.
    #[derive(Debug, Clone)]
    pub struct TokenizeClient<T> {
        inner: tonic::client::Grpc<T>,
    }
    impl TokenizeClient<tonic::transport::Channel> {
        /// Attempt to create a new client by connecting to a given endpoint.
        pub async fn connect<D>(dst: D) -> Result<Self, tonic::transport::Error>
        where
            D: TryInto<tonic::transport::Endpoint>,
            D::Error: Into<StdError>,
        {
            let conn = tonic::transport::Endpoint::new(dst)?.connect().await?;
            Ok(Self::new(conn))
        }
    }
    impl<T> TokenizeClient<T>
    where
        T: tonic::client::GrpcService<tonic::body::Body>,
        T::Error: Into<StdError>,
        T::ResponseBody: Body<Data = Bytes> + std::marker::Send + 'static,
        <T::ResponseBody as Body>::Error: Into<StdError> + std::marker::Send,
    {
        pub fn new(inner: T) -> Self {
            let inner = tonic::client::Grpc::new(inner);
            Self { inner }
        }
        pub fn with_origin(inner: T, origin: Uri) -> Self {
            let inner = tonic::client::Grpc::with_origin(inner, origin);
            Self { inner }
        }
        pub fn with_interceptor<F>(
            inner: T,
            interceptor: F,
        ) -> TokenizeClient<InterceptedService<T, F>>
        where
            F: tonic::service::Interceptor,
            T::ResponseBody: Default,
            T: tonic::codegen::Service<
                http::Request<tonic::body::Body>,
                Response = http::Response<
                    <T as tonic::client::GrpcService<tonic::body::Body>>::ResponseBody,
                >,
            >,
            <T as tonic::codegen::Service<
                http::Request<tonic::body::Body>,
            >>::Error: Into<StdError> + std::marker::Send + std::marker::Sync,
        {
            TokenizeClient::new(InterceptedService::new(inner, interceptor))
        }
        /// Compress requests with the given encoding.
        ///
        /// This requires the server to support it otherwise it might respond with an
        /// error.
        #[must_use]
        pub fn send_compressed(mut self, encoding: CompressionEncoding) -> Self {
            self.inner = self.inner.send_compressed(encoding);
            self
        }
        /// Enable decompressing responses.
        #[must_use]
        pub fn accept_compressed(mut self, encoding: CompressionEncoding) -> Self {
            self.inner = self.inner.accept_compressed(encoding);
            self
        }
        /// Limits the maximum size of a decoded message.
        ///
        /// Default: `4MB`
        #[must_use]
        pub fn max_decoding_message_size(mut self, limit: usize) -> Self {
            self.inner = self.inner.max_decoding_message_size(limit);
            self
        }
        /// Limits the maximum size of an encoded message.
        ///
        /// Default: `usize::MAX`
        #[must_use]
        pub fn max_encoding_message_size(mut self, limit: usize) -> Self {
            self.inner = self.inner.max_encoding_message_size(limit);
            self
        }
        /// Convert text to a sequence of tokens.
        pub async fn tokenize_text(
            &mut self,
            request: impl tonic::IntoRequest<super::TokenizeTextRequest>,
        ) -> std::result::Result<
            tonic::Response<super::TokenizeTextResponse>,
            tonic::Status,
        > {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::unknown(
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic_prost::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/xai_api.Tokenize/TokenizeText",
            );
            let mut req = request.into_request();
            req.extensions_mut()
                .insert(GrpcMethod::new("xai_api.Tokenize", "TokenizeText"));
            self.inner.unary(req, path, codec).await
        }
    }
}
